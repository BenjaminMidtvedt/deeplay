{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction for Developers\n",
    "\n",
    "This notebook presents a minimal example of how to implement a neural network and and an application with deeplay.\n",
    "Specifically, it implements the classes for a multilayer perceptron and a classifier.\n",
    "Then, it combines them to demonstrate how tehy can be used for a simple classification task.\n",
    "Finally, it upgrades these classes adding functionalities that are required to improved the user experience when using an IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Multilayer Perceptron\n",
    "\n",
    "Here, we implement the minimal class `SimpleMLP`. It extends directly `dl.DeeplayModule`, which is the base class for all modules in `deeplay`.\n",
    "\n",
    "It represents a multilayer perceptron with a certain umber of inputs (`Ã¬n_features`, which is an integer), a series of hidden layers with a certain number of neurons (`hidden_features`, a vector with the number of neurons for each layer), and a certain numebr of outputs (`out_features`, which is an integer).\n",
    "\n",
    "The constructor initializes the MLP by creating a sequence of linear and ReLU activation layers.\n",
    "\n",
    "The `forward` method defines the data flow through the network, sequentially passing the input through each linear-activation block and returning the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleMLP(dl.DeeplayModule):\n",
    "\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks = dl.LayerList()\n",
    "        for inputs_layer, outputs_layer in zip([in_features, *hidden_features], \n",
    "                                               [*hidden_features, out_features]):\n",
    "            self.blocks.append(\n",
    "                dl.LayerActivationBlock(\n",
    "                    dl.Layer(nn.Linear, inputs_layer, outputs_layer),\n",
    "                    dl.Layer(nn.ReLU)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create an instance of `SimpleMLP` in various ways, for example:\n",
    "\n",
    "```python\n",
    "mlp = SimpleMLP(2, [32, 32], 2)\n",
    "```\n",
    "\n",
    "or more explicitly:\n",
    "\n",
    "```python\n",
    "mlp = SimpleMLP(\n",
    "    in_features=2, \n",
    "    hidden_feature=[32, 32], \n",
    "    out_features=2\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = SimpleMLP(2, [32, 32], 2)\n",
    "\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Classifier\n",
    "\n",
    "Here, we now implement the application `SimpleClassifier`. This extend the deeplay class `dl.Application`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(dl.Application):\n",
    "\n",
    "    def __init__(self, model, **kwargs):\n",
    "        self.model = model\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create an instance of this using as model the `mlp` that we have defined above, setting `loss` to `nn.CrossEntropyLoss()` and `optimizer`to `dl.Adam(lr=1e-3)`. We also add kepp track of a metrics, setting `metrics` to `[tm.Accuracy(\"multiclass\", num_classes=2)]`.\n",
    "\n",
    "Since we are using a cross-entropy loss, we need to set the output activation to `nn.Identity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics as tm\n",
    "\n",
    "classifier = SimpleClassifier(\n",
    "    model=mlp, \n",
    "    loss=nn.CrossEntropyLoss(), \n",
    "    optimizer=dl.Adam(lr=1e-3), \n",
    "    metrics=[tm.Accuracy(\"multiclass\", num_classes=2)]\n",
    ")\n",
    "classifier.model.blocks[-1].activation.configure(nn.Identity)\n",
    "\n",
    "classifier.build()\n",
    "\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "Instead of `classifier.build()`, which build the module in place, it is also possible to use `new_classifier = classifier.create()`, which clones and build the classifier.\n",
    "\n",
    "Instead of `classifier.model.blocks[-1].activation.configure(nn.Identity)`, it'd also be possible to use `classifier.model.blocks[-1].activation.configure(nn.Identity)`, which is more easily understandable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "We'll now use `classifier` for the simple task of determinig whether the sum of two numbers is larger or smaller than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import randn\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "\n",
    "num_samples = 100\n",
    "data = randn(num_samples, 2)\n",
    "labels = (data.sum(dim=1) > 0).long()\n",
    "\n",
    "dataset = TensorDataset(data, labels)\n",
    "train, val = random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val, batch_size=16, shuffle=False)\n",
    "\n",
    "trainer = dl.Trainer(max_epochs=10)\n",
    "\n",
    "trainer.fit(classifier, train_dataloader, val_dataloader)\n",
    "\n",
    "trainer.test(classifier, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality-of-Life Improvements for IDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
