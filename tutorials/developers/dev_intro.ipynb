{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to DEEPLAY for Developers\n",
    "\n",
    "This notebook presents a minimal example of how to implement a neural network and and an application with deeplay.\n",
    "Specifically, it implements the classes for a multilayer perceptron and a classifier.\n",
    "Then, it combines them to demonstrate how tehy can be used for a simple classification task.\n",
    "Finally, it upgrades these classes adding functionalities that are required to improved the user experience when using an IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Multilayer Perceptron\n",
    "\n",
    "Here, we implement the minimal class `SimpleMLP` that represents a multilayer perceptron with a certain umber of inputs (`Ã¬n_features`, which is an integer), a series of hidden layers with a certain number of neurons (`hidden_features`, a vector with the number of neurons for each layer), and a certain numebr of outputs (`out_features`, which is an integer).\n",
    "\n",
    "The constructor initializes the MLP by creating a sequence of linear and ReLU activation layers.\n",
    "\n",
    "The `forward` method defines the data flow through the network, sequentially passing the input through each linear-activation block and returning the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplay as dl\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleMLP(dl.DeeplayModule):\n",
    "\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks = dl.LayerList()\n",
    "        for inputs_layer, outputs_layer in zip([in_features, *hidden_features], \n",
    "                                               [*hidden_features, out_features]):\n",
    "            self.blocks.append(\n",
    "                dl.LayerActivationBlock(\n",
    "                    dl.Layer(nn.Linear, inputs_layer, outputs_layer),\n",
    "                    dl.Layer(nn.ReLU)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create an instance of `SimpleMLP` in various ways, for example:\n",
    "\n",
    "```python\n",
    "mlp = SimpleMLP(2, [32, 32], 2)\n",
    "```\n",
    "\n",
    "or more explicitly:\n",
    "\n",
    "```python\n",
    "mlp = SimpleMLP(\n",
    "    in_features=2, \n",
    "    hidden_feature=[32, 32], \n",
    "    out_features=2\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = SimpleMLP(2, [32, 32], 2)\n",
    "\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal classifier\n",
    "import torchmetrics as tm\n",
    "\n",
    "class Classifier(dl.Application):\n",
    "\n",
    "    def __init__(self, model, **kwargs):\n",
    "        self.model = model\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "classifier = Classifier(\n",
    "    mlp, \n",
    "    loss=nn.CrossEntropyLoss(), \n",
    "    optimizer=dl.Adam(lr=1e-3), \n",
    "    metrics=[tm.Accuracy(\"multiclass\", num_classes=2)]\n",
    ")\n",
    "\n",
    "classifier.model.blocks[-1].activation.configure(nn.Identity)\n",
    "classifier.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example:\n",
    "\n",
    "import torch\n",
    "n_samples = 10000\n",
    "train_data = torch.rand(n_samples, 2)\n",
    "train_labels = (train_data.sum(dim=1) > 1).long()\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(train_data, train_labels)\n",
    "train, val = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val, batch_size=16, shuffle=False)\n",
    "\n",
    "trainer = dl.Trainer(max_epochs=10)\n",
    "\n",
    "trainer.fit(classifier, train_dataloader, val_dataloader)\n",
    "trainer.test(classifier, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality-of-Life Improvements for IDE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
