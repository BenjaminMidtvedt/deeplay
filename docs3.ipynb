{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components\n",
    "\n",
    "Components are usually constructed by combining multiple blocks. As opposed to models, they don't have a default architecture. Instead, the architecture (including the number of features in each layer) is passed as arguments to the constructor. This makes components more flexible than models, but also more complex to use. Models are usually constructed by combining multiple components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available components\n",
    "\n",
    "### MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (blocks): LayerList(\n",
      "    (0): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=10, out_features=20, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=20, out_features=30, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (2): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=30, out_features=40, bias=True)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (3): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=40, out_features=5, bias=True)\n",
      "      (activation): Layer[Tanh]()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import deeplay as dl\n",
    "import torch.nn as nn\n",
    "\n",
    "mlp = dl.MultiLayerPerceptron(\n",
    "    in_features=10,\n",
    "    hidden_features=[20, 30, 40],\n",
    "    out_features=5,\n",
    "    out_activation=dl.torch.nn.Tanh,\n",
    ")\n",
    "\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvolutionalNeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalNeuralNetwork(\n",
      "  (blocks): LayerList(\n",
      "    (0): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (normalization): Layer[BatchNorm2d](num_features=16)\n",
      "    )\n",
      "    (1): Conv2dBlock(\n",
      "      (pool): Layer[MaxPool2d](kernel_size=2)\n",
      "      (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (normalization): Layer[BatchNorm2d](num_features=32)\n",
      "    )\n",
      "    (2): Conv2dBlock(\n",
      "      (pool): Layer[MaxPool2d](kernel_size=2)\n",
      "      (layer): Layer[Conv2d](in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (normalization): Layer[BatchNorm2d](num_features=64)\n",
      "    )\n",
      "    (3): Conv2dBlock(\n",
      "      (pool): Layer[MaxPool2d](kernel_size=2)\n",
      "      (layer): Layer[Conv2d](in_channels=64, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[Tanh]()\n",
      "      (normalization): Layer[BatchNorm2d](num_features=10)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = dl.ConvolutionalNeuralNetwork(\n",
    "    in_channels=3,\n",
    "    hidden_channels=[16, 32, 64],\n",
    "    out_channels=10,\n",
    "    out_activation=dl.torch.nn.Tanh,\n",
    "    pool=dl.Layer(nn.MaxPool2d, kernel_size=2),\n",
    ")\n",
    "\n",
    "cnn.normalized(\n",
    "    dl.Layer(nn.BatchNorm2d),\n",
    "    after_last_layer=True,\n",
    "    mode=\"append\"\n",
    ")\n",
    "\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalEncoder2d(\n",
      "  (blocks): LayerList(\n",
      "    (0): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=3, stride=2, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (1): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (2): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "    )\n",
      "    (3): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=64, out_channels=10, kernel_size=3, stride=2, padding=1)\n",
      "      (activation): Layer[Tanh]()\n",
      "    )\n",
      "  )\n",
      "  (postprocess): Layer[Identity]()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = dl.ConvolutionalEncoder2d(\n",
    "    in_channels=3,\n",
    "    hidden_channels=[16, 32, 64],\n",
    "    out_channels=10,\n",
    "    out_activation=dl.torch.nn.Tanh,\n",
    ")\n",
    "\n",
    "encoder.strided(stride=2, apply_to_first_layer=True, apply_to_last_layer=True)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvolutionalDecoder2d(\n",
      "  (blocks): LayerList(\n",
      "    (0): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=10, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (upsample): Layer[Upsample](scale_factor=2)\n",
      "    )\n",
      "    (1): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (upsample): Layer[Upsample](scale_factor=2)\n",
      "    )\n",
      "    (2): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (upsample): Layer[Upsample](scale_factor=2)\n",
      "    )\n",
      "    (3): Conv2dBlock(\n",
      "      (layer): Layer[Conv2d](in_channels=16, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
      "      (activation): Layer[Tanh]()\n",
      "      (upsample): Layer[Upsample](scale_factor=2)\n",
      "    )\n",
      "  )\n",
      "  (preprocess): Layer[Identity]()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "decoder = dl.ConvolutionalDecoder2d(\n",
    "    in_channels=10,\n",
    "    hidden_channels=[64, 32, 16],\n",
    "    out_channels=3,\n",
    "    out_activation=dl.torch.nn.Tanh,\n",
    ")\n",
    "\n",
    "decoder.upsampled(\n",
    "    dl.Layer(nn.Upsample, scale_factor=2),\n",
    "    apply_to_last_layer=True, \n",
    ")\n",
    "\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecurrentNeuralNetwork(\n",
      "  (blocks): LayerList(\n",
      "    (0): Sequence1dBlock(\n",
      "      (layer): Layer[LSTM](input_size=10, hidden_size=20, batch_first=True)\n",
      "    )\n",
      "    (1): Sequence1dBlock(\n",
      "      (layer): Layer[LSTM](input_size=20, hidden_size=30, batch_first=True)\n",
      "    )\n",
      "    (2): Sequence1dBlock(\n",
      "      (layer): Layer[LSTM](input_size=30, hidden_size=40, batch_first=True)\n",
      "    )\n",
      "    (3): Sequence1dBlock(\n",
      "      (layer): Layer[LSTM](input_size=40, hidden_size=5, batch_first=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "rnn = dl.RecurrentNeuralNetwork(\n",
    "    in_features=10,\n",
    "    hidden_features=[20, 30, 40],\n",
    "    out_features=5,\n",
    "    batch_first=True,\n",
    "    return_cell_state=False,\n",
    ")\n",
    "\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blocks\n",
    "\n",
    "Blocks are the most versatile part of deeplay. They are designed to be be transformed from a base block to any other block that accepts the same input tensor shape and returns the same output tensor shape. We'll show how to do this in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearBlock(\n",
      "  (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      ")\n",
      "LinearBlock(\n",
      "  (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "  (activation): Layer[ReLU]()\n",
      ")\n",
      "LinearBlock(\n",
      "  (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "  (normalization): Layer[LayerNorm](normalized_shape=10)\n",
      "  (activation): Layer[ReLU]()\n",
      ")\n",
      "LinearBlock(\n",
      "  (shortcut_start): Layer[Identity]()\n",
      "  (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "  (normalization): Layer[LayerNorm](normalized_shape=10)\n",
      "  (activation): Layer[ReLU]()\n",
      "  (shortcut_end): Add()\n",
      ")\n",
      "LinearBlock(\n",
      "  (shortcut_start): Layer[Identity]()\n",
      "  (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "  (normalization): Layer[LayerNorm](normalized_shape=10)\n",
      "  (activation): Layer[ReLU]()\n",
      "  (shortcut_end): Add()\n",
      "  (dropout): Layer[Dropout](p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = dl.LinearBlock(4, 10)\n",
    "print(block)\n",
    "\n",
    "block.activated(nn.ReLU)\n",
    "print(block)\n",
    "\n",
    "block.normalized(nn.LayerNorm, mode=\"insert\", after=\"layer\")\n",
    "print(block)\n",
    "\n",
    "block.shortcut()\n",
    "print(block)\n",
    "\n",
    "block.set_dropout(0.2)\n",
    "print(block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearBlock(\n",
      "  (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      ")\n",
      "LinearBlock(\n",
      "  (blocks): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "LinearBlock(\n",
      "  (blocks): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (shortcut_start): Layer[Identity]()\n",
      "      (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "      (normalization): Layer[LayerNorm](normalized_shape=10)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (shortcut_end): Add()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (shortcut_start): Layer[Identity]()\n",
      "      (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "      (normalization): Layer[LayerNorm](normalized_shape=10)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (shortcut_end): Add()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "LinearBlock(\n",
      "  (blocks): Sequential(\n",
      "    (0): LinearBlock(\n",
      "      (shortcut_start): Layer[Identity]()\n",
      "      (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "      (normalization): Layer[LayerNorm](normalized_shape=10)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (shortcut_end): Add()\n",
      "    )\n",
      "    (1): LinearBlock(\n",
      "      (shortcut_start): Layer[Identity]()\n",
      "      (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "      (normalization): Layer[LayerNorm](normalized_shape=10)\n",
      "      (activation): Layer[ReLU]()\n",
      "      (shortcut_end): Add()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Layer[Dropout](p=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = dl.LinearBlock(4, 10)\n",
    "print(block)\n",
    "\n",
    "block.multi(2)\n",
    "print(block)\n",
    "\n",
    "block[\"blocks\"].all \\\n",
    "    .activated(nn.ReLU) \\\n",
    "    .normalized(nn.LayerNorm, mode=\"insert\", after=\"layer\") \\\n",
    "    .shortcut()\n",
    "print(block)\n",
    "\n",
    "block.set_dropout(0.2)\n",
    "print(block)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv2dBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dBlock(\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conv2dBlock(\n",
       "  (shortcut_start): Conv2dBlock(\n",
       "    (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=2, padding=0)\n",
       "    (activation): Layer[Identity]()\n",
       "  )\n",
       "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=2, padding=0)\n",
       "  (normalization): Layer[LayerNorm](normalized_shape=10)\n",
       "  (activation): Layer[ReLU]()\n",
       "  (shortcut_end): Add()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = dl.Conv2dBlock(3, 10, kernel_size=1)\n",
    "print(block)\n",
    "\n",
    "block.activated(nn.ReLU) \\\n",
    "    .normalized(nn.LayerNorm, mode=\"insert\", after=\"layer\") \\\n",
    "    .strided(2) \\\n",
    "    .shortcut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dBlock(\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      "  (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0)\n",
      ")\n",
      "Conv2dBlock(\n",
      "  (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = dl.Conv2dBlock(3, 10, kernel_size=1).upsampled()\n",
    "print(block)\n",
    "\n",
    "block = dl.Conv2dBlock(3, 10, kernel_size=1).pooled()\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence1dBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence1dBlock(\n",
      "  (layer): Layer[LSTM](input_size=4, hidden_size=10, batch_first=False)\n",
      ")\n",
      "Sequence1dBlock(\n",
      "  (layer): Layer[GRU](input_size=4, hidden_size=10, batch_first=False)\n",
      ")\n",
      "Sequence1dBlock(\n",
      "  (layer): Layer[RNN](input_size=4, hidden_size=10, batch_first=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = dl.Sequence1dBlock(4, 10).LSTM()\n",
    "print(block)\n",
    "\n",
    "block = dl.Sequence1dBlock(4, 10).GRU()\n",
    "print(block)\n",
    "\n",
    "block = dl.Sequence1dBlock(4, 10).RNN()\n",
    "print(block)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lower level block methods\n",
    "\n",
    "Blocks work through named layers executed sequentially based on a list containing the layer names. This can be configured directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearBlock(\n",
      "  (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "  (activation): Layer[ReLU]()\n",
      "  (normalization): Layer[BatchNorm1d](num_features=10)\n",
      ")\n",
      "LinearBlock(\n",
      "  (layer): Layer[Linear](in_features=4, out_features=10, bias=True)\n",
      "  (normalization): Layer[BatchNorm1d](num_features=10)\n",
      "  (activation): Layer[ReLU]()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = dl.LinearBlock(4, 10).activated(nn.ReLU).normalized()\n",
    "print(block)\n",
    "\n",
    "block.configure(order=[\"layer\", \"normalization\", \"activation\"])\n",
    "print(block)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a layer to a block, there are a few methods available:\n",
    "- `append`\n",
    "- `prepend`\n",
    "- `insert`\n",
    "- `set`\n",
    "\n",
    "Let's see how to use them.\n",
    "\n",
    "### `append`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dBlock(\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      ")\n",
      "Conv2dBlock(\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      "  (relu): Layer[ReLU]()\n",
      ")\n",
      "Conv2dBlock(\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      "  (relu): Layer[ReLU]()\n",
      "  (normalization): Layer[LayerNorm]()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = dl.Conv2dBlock(3, 10, kernel_size=1)\n",
    "print(block)\n",
    "\n",
    "block.append(dl.Layer(nn.ReLU))\n",
    "print(block) # The name of the layer is automatically set to \"relu\" based on the class name\n",
    "\n",
    "block.append(dl.Layer(nn.LayerNorm), name=\"normalization\")\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `prepend`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dBlock(\n",
      "  (pool): Layer[MaxPool2d](kernel_size=2)\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = dl.Conv2dBlock(3, 10, kernel_size=1)\n",
    "block.prepend(dl.Layer(nn.MaxPool2d, kernel_size=2), name=\"pool\")\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `insert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dBlock(\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      "  (normalization): Layer[LayerNorm]()\n",
      "  (activation): Layer[ReLU]()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = dl.Conv2dBlock(3, 10, kernel_size=1).activated(nn.ReLU)\n",
    "block.insert(dl.Layer(nn.LayerNorm), after=\"layer\", name=\"normalization\")\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `set`\n",
    "\n",
    "Unlike previous methods, `set` will replace the layer with the given name if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dBlock(\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      "  (activation): Layer[ReLU]()\n",
      ")\n",
      "Conv2dBlock(\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      "  (activation): Layer[ReLU]()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block_without_activation = dl.Conv2dBlock(3, 10, kernel_size=1)\n",
    "block_with_activation = dl.Conv2dBlock(3, 10, kernel_size=1).activated(nn.ReLU) \n",
    "\n",
    "block_without_activation.set(\"activation\", nn.ReLU)\n",
    "block_with_activation.set(\"activation\", nn.ReLU)\n",
    "print(block_without_activation)\n",
    "print(block_with_activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers can be removed using the `remove` method, which removes based on the layer name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dBlock(\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      "  (activation): Layer[ReLU]()\n",
      ")\n",
      "Conv2dBlock(\n",
      "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "block = dl.Conv2dBlock(3, 10, kernel_size=1).activated(nn.ReLU)\n",
    "print(block)\n",
    "\n",
    "block.remove(\"activation\")\n",
    "print(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations\n",
    "\n",
    "Operations are special layers that are implemented in deeplay directly. They are not blocks, but can be used as layers in blocks. They are used to perform operations that are not implemented in PyTorch, such as `Flatten` or `Reshape`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5])\n",
      "torch.Size([2, 6, 4, 5])\n",
      "torch.Size([2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "merge_add = dl.ops.Add().build()\n",
    "merge_cat = dl.ops.Cat(dim=1).build()\n",
    "merge_lam = dl.ops.Lambda(lambda x: x[0] + x[1]).build()\n",
    "\n",
    "x = torch.randn(2, 3, 4, 5)\n",
    "y = torch.randn(2, 3, 4, 5)\n",
    "\n",
    "print(merge_add(x, y).shape)\n",
    "print(merge_cat(x, y).shape)\n",
    "print(merge_lam(x, y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dBlock(\n",
       "  (shortcut_start): Conv2dBlock(\n",
       "    (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
       "    (activation): Layer[Identity]()\n",
       "  )\n",
       "  (layer): Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=1, padding=0)\n",
       "  (activation): Layer[ReLU]()\n",
       "  (shortcut_end): Cat()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = dl.Conv2dBlock(3, 10, kernel_size=1).activated(nn.ReLU)\n",
    "block.shortcut(merge=merge_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 10])\n",
      "torch.Size([2, 60])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4, 5)\n",
    "\n",
    "reshape = dl.ops.Reshape(-1, 10)\n",
    "reshape_func = dl.ops.Reshape(lambda shape: (shape[0], -1))\n",
    "\n",
    "print(reshape(x).shape)\n",
    "print(reshape_func(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 1])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 1, 3, 1)\n",
    "squeeze = dl.ops.Squeeze(dim=1)\n",
    "squeeze_all = dl.ops.Squeeze()\n",
    "\n",
    "print(squeeze(x).shape)\n",
    "print(squeeze_all(x).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4, 5)\n",
    "unsqueeze = dl.ops.Unsqueeze(dim=1)\n",
    "\n",
    "print(unsqueeze(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4, 5)\n",
    "flatten = dl.ops.Flatten(start_dim=1, end_dim=2)\n",
    "print(flatten(x).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4, 5)\n",
    "permute = dl.ops.Permute(0, 2, 1, 3)\n",
    "print(permute(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The configure method\n",
    "\n",
    "The configure method exists on all DeeplayModule classes. It works by changing the input parameters of the constructor of the class, and subsequently re-initializing the class. For `Layer` classes, the configure method will instead affect the constructor argument of the classtype of the layer. For example, `Layer(nn.Conv2d, 8, 8).configure(kernel_size=5)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLayerPerceptron(\n",
       "  (blocks): LayerList(\n",
       "    (0): LinearBlock(\n",
       "      (layer): Layer[Linear](in_features=10, out_features=20, bias=True)\n",
       "      (activation): Layer[ReLU]()\n",
       "    )\n",
       "    (1): LinearBlock(\n",
       "      (layer): Layer[Linear](in_features=20, out_features=30, bias=True)\n",
       "      (activation): Layer[ReLU]()\n",
       "    )\n",
       "    (2): LinearBlock(\n",
       "      (layer): Layer[Linear](in_features=30, out_features=40, bias=True)\n",
       "      (activation): Layer[ReLU]()\n",
       "    )\n",
       "    (3): LinearBlock(\n",
       "      (layer): Layer[Linear](in_features=40, out_features=5, bias=True)\n",
       "      (activation): Layer[Tanh]()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = dl.MultiLayerPerceptron(\n",
    "    in_features=10,\n",
    "    hidden_features=[20, 30, 40],\n",
    "    out_features=5,\n",
    ")\n",
    "\n",
    "mlp.configure(out_activation=nn.Tanh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer[Conv2d](in_channels=3, out_channels=10, kernel_size=1, stride=2)\n"
     ]
    }
   ],
   "source": [
    "layer = dl.Layer(nn.Conv2d, in_channels=3, out_channels=10, kernel_size=1)\n",
    "layer.configure(stride=2)\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When configuring a Layer, the first positional argument can be used to change the class type of the layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer[ReLU]()\n",
      "Layer[LeakyReLU](negative_slope=0.1)\n"
     ]
    }
   ],
   "source": [
    "layer = dl.Layer(nn.ReLU)\n",
    "print(layer)\n",
    "layer.configure(nn.LeakyReLU, negative_slope=0.1)\n",
    "print(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selections\n",
    "\n",
    "Selections are a way to apply an operation or configuration to multiple classes at once. There is some special syntax, which is easier to understand through examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder',)]\n",
      "[('encoder', 'blocks')]\n",
      "[('encoder',), ('decoder',)]\n",
      "[('encoder',), ('bottleneck',), ('decoder',), ('skip',)]\n",
      "[('encoder', 'blocks', '0', 'layer'), ('encoder', 'blocks', '1', 'layer'), ('bottleneck', 'blocks', '0', 'layer'), ('decoder', 'blocks', '0', 'layer'), ('decoder', 'blocks', '1', 'layer')]\n",
      "[('encoder', 'blocks', '0', 'layer'), ('encoder', 'blocks', '1', 'layer')]\n",
      "[('encoder', 'blocks', '0', 'layer'), ('decoder', 'blocks', '1', 'layer')]\n",
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=1, stride=1, padding=0)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[ReLU]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Tanh]()\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = dl.UNet2d(\n",
    "    in_channels=3,\n",
    "    encoder_channels=[16, 32],\n",
    "    out_channels=10,\n",
    "    out_activation=nn.Tanh,\n",
    ")\n",
    "# print(model)\n",
    "\n",
    "# Strings are used to select a direct child\n",
    "print(model[\"encoder\"].list_names())\n",
    "\n",
    "# Multiple strings can be used to select multiple successive children\n",
    "print(model[\"encoder\", \"blocks\"].list_names())\n",
    "\n",
    "# The | operator can be used to select multiple children at the same level\n",
    "print(model[\"encoder|decoder\"].list_names())\n",
    "\n",
    "# The : operator can be used to select all children at the same level\n",
    "print(model[:].list_names())\n",
    "\n",
    "# The ... operator can be used to select select all children at any level\n",
    "print(model[..., \"layer\"].list_names()) # Here, we first select all children at any level, then we select only the children named \"layer\"\n",
    "\n",
    "# The # operator can be used to select a subset of previously selected children\n",
    "print(model[..., \"layer#0:2\"].list_names())\n",
    "\n",
    "# The , operator can be used to select either of multiple selectors\n",
    "print(model[..., \"layer#0, layer#-1\"].list_names())\n",
    "\n",
    "# Lets select the first block of the encoder and change the kernel size\n",
    "model[..., \"layer#0\"].configure(kernel_size=1, padding=0)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selection can be filtered using the methods:\n",
    "- `filter`\n",
    "- `hasattr`\n",
    "- `isinstance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('encoder',)]\n",
      "[('encoder', 'blocks', '0', 'activation'), ('encoder', 'blocks', '1', 'activation')]\n",
      "[('encoder', 'blocks', '0'), ('encoder', 'blocks', '1'), ('bottleneck', 'blocks', '0'), ('decoder', 'blocks', '0'), ('decoder', 'blocks', '1')]\n",
      "[('encoder', 'blocks', '0'), ('encoder', 'blocks', '1'), ('bottleneck', 'blocks', '0'), ('decoder', 'blocks', '0'), ('decoder', 'blocks', '1')]\n"
     ]
    }
   ],
   "source": [
    "print(model[...].isinstance(dl.ConvolutionalEncoder2d).list_names())\n",
    "print(model[\"encoder\", ...].isinstance(nn.ReLU).list_names())\n",
    "print(model[...].hasattr(\"pool\").list_names()) # TODO: bugged. should not return decoder.\n",
    "print(model[...].hasattr(\"stride\").list_names()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any method can be applied to the selection, not just `configure`. This will either apply the method to all classes in the selection, or to the first class in the selection. You can choose which one by accessing the `all` or `first` attributes of the selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2d(\n",
      "  (encoder): ConvolutionalEncoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (normalization): Layer[BatchNorm2d](num_features=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (normalization): Layer[BatchNorm2d](num_features=32)\n",
      "      )\n",
      "    )\n",
      "    (postprocess): Layer[Identity]()\n",
      "  )\n",
      "  (bottleneck): ConvolutionalNeuralNetwork(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (pool): Layer[MaxPool2d](kernel_size=2, stride=2)\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0)\n",
      "        (normalization): Layer[BatchNorm2d](num_features=32)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): ConvolutionalDecoder2d(\n",
      "    (blocks): LayerList(\n",
      "      (0): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=64, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (upsample): Layer[ConvTranspose2d](kernel_size=2, stride=2, padding=0)\n",
      "        (normalization): Layer[BatchNorm2d](num_features=16)\n",
      "      )\n",
      "      (1): Conv2dBlock(\n",
      "        (layer): Layer[Conv2d](in_channels=32, out_channels=10, kernel_size=3, stride=1, padding=1)\n",
      "        (activation): Layer[Sigmoid]()\n",
      "        (normalization): Layer[BatchNorm2d](num_features=10)\n",
      "      )\n",
      "    )\n",
      "    (preprocess): Layer[Identity]()\n",
      "  )\n",
      "  (skip): Cat()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model[..., \"layer\"].first.configure(kernel_size=5, padding=2)\n",
    "model[..., \"activation\"].all.configure(nn.Sigmoid)\n",
    "model[...].isinstance(dl.Conv2dBlock).all.normalized(nn.BatchNorm2d)\n",
    "model[...].isinstance(nn.BatchNorm2d).all.initialize(dl.initializers.Constant(weight=1, bias=0))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deeplay.vision\n",
    "\n",
    "Does not exist yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deeplay.language\n",
    "\n",
    "Does not exist yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deeplay.geometric\n",
    "\n",
    "Does not exist yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deeplay.activelearning\n",
    "\n",
    "Contains tools for active learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2a9e7751150>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHNUlEQVR4nO3df3xU1Z038M8klQQkMwpWkmDUSN3SNCpqC/5qS338kYogrdqtT63o+mIrC/vI0j4L+OrKw/YH0vJa2doWfXxasc1adGktYN3s0tIqVhDXLCsx4i68ArKQCIY6ExECOzPPH5c7ZCb3zv0x99xzzr2f9+vFKyVMksMM9XznnO+PRD6fz4OIiIhIgirZCyAiIqL4YiBCRERE0jAQISIiImkYiBAREZE0DESIiIhIGgYiREREJA0DESIiIpKGgQgRERFJ8yHZCygnl8vhwIEDqKurQyKRkL0cIiIiciGfz2NgYACNjY2oqip/5qF0IHLgwAE0NTXJXgYRERH5sG/fPpxzzjllH6N0IFJXVwfA+Iskk0nJqyEiIiI3MpkMmpqaCvt4OUoHIuZ1TDKZZCBCRESkGTdpFUxWJSIiImkYiBAREZE0DESIiIhIGgYiREREJA0DESIiIpKGgQgRERFJw0CEiIiIpGEgQkRERNIo3dCM5Mnm8tjWcxgHB47h7LpaTG4eg+oqzvshIqJgMRChYTq6erF0Qzd608cKn2tI1WLJ9Ba0tTZIXBkREUUNr2aoSEdXL+a0dxYFIQDQlz6GOe2d6OjqlbSyeMnm8tiyux/rtu/Hlt39yObyspdERCQET0SoIJvLY+mGblhteXkACQBLN3Tj+pZ6XtMIxBMpIooTnohQwbaew8NOQobKA+hNH8O2nsPhLSpmeCJFRHHDQIQKDg7YByF+HkfeOJ1IAcaJFK9piChKGIhQwdl1tYE+jrzhiRQRxREDESqY3DwGDala2GV/JGDkKkxuHhPmsmKDJ1JEFEcMRKiguiqBJdNbAGBYMGL+fsn0FiaqCsITKSKKIwYiVKSttQGr7rwM9aniza4+VYtVd17Gqg2BeCJFRHHE8l0apq21Ade31LOzasjME6k57Z1IAEVJqzyRIqKoSuTzeWVT8DOZDFKpFNLpNJLJpOzlEIWCfUSISHde9m+eiBAphidSRBQnDESIFFRdlcCVE8bKXgYRkXAMRIiIoiKXBfa+DLz/DjB6HHDeVUBVtexVEZXFQISIKAq61wMdC4HMgVOfSzYCbcuBlhny1kXkgOW7RES6614PPHNXcRACAJle4/Pd6+Wsi8gFBiJERDrLZY2TkHJTijoWGY8jUhADESIine19efhJSJE8kNlvPI5IQQxEiIh09v47wT6OKGQMRIiIdDZ6XLCPIwoZAxEiIp2dd5VRHVNuSlFyvPE4IgUxECEi0llVtVGiC8B2bnbbQ+wnQspiIEJEpLuWGcAXfwokS2YRJRuNz7OPCCmMDc2IiKKgZQYwcRo7q5J2GIgQEUVFVTXQ/CnZq1AD291rg4EIERFFC9vda4U5IkQlsrk8tuzux7rt+7Fldz+yOauOlUSkJLa71w5PRIiG6OjqxdIN3ehNHyt8riFViyXTW9DW2lDmK4lIOsd29wmj3f3EabymUQhPRIhO6ujqxZz2zqIgBAD60scwp70THV29klZG0uSyQM9mYMda4yPntaiN7e61xBMRIhjXMUs3dJd7H4WlG7pxfUs9qqvsGkdRpDDPQD9sd68lnogQAdjWc3jYSchQeQC96WPY1nM4vEWRPMwz0BPb3WuJgQgRgIMD9kGIn8eRxhzzDGDkGfCaRj1sd68lBiJEAM6uqw30caSxoPMMmGcSHra71xJzRIgATG4eg4ZULfrSxyzfBycA1KdqMbl5TNhLo7AFmWfAPJPwme3uLZ/3h/i8K4iBCBGA6qoElkxvwZz2TiRQfChvvq9aMr2FiapxEFSegZlnUhramnkmnAEjDtvda4VXM0QntbU2YNWdl6E+VXz9Up+qxao7L2MfkbgIIs+AeSbyme3uL7rN+MggRFk8ESEaoq21Ade31GNbz2EcHDiGs+uM6xiehMSImWfwzF2A3fmYU56BlzwTzoahmGMgQlSiuiqBKyeMlb0MkqnSPAP2syByjYEIEZGVSvIM2M+CyDUGIkREdsw8A6/MPJNML6zzRBLGn7OfBRGTVYmIAsd+FkSuMRAhIhLBzDNJllRbJRtZuks0BK9mKJKyuTwrX0g+9rMgciQ0EFm2bBl++ctfYufOnRg5ciSuuuoqLF++HB/96EdF/liKuY6uXizd0F00xK4hVYsl01vYC4TC5zfPhCgmhF7NvPDCC5g7dy62bt2KjRs34sSJE7jhhhtw5MgRkT+WYqyjqxdz2juHTdLtSx/DnPZOdHT1SloZERFZSeTzeauUbiEOHTqEs88+Gy+88AI+/elPOz4+k8kglUohnU4jmUyGsELSWTaXxzXLNw0LQkzmvJiXFl7LaxoiIoG87N+h5oik02kAwJgx1oPDBgcHMTg4WPh9JpMJZV0UDdt6DtsGIYBRRNmbPoZtPYdDa1jGXBUiovJCC0RyuRzmz5+Pq6++Gq2trZaPWbZsGZYuXRrWkihiDg7YByF+Hlcp5qoQETkLrXx37ty56Orqwpo1a2wfs3jxYqTT6cKvffv2hbU8ioCz62qdH+ThcZVgrgoRkTuhBCLz5s3Dc889h9/97nc455xzbB9XU1ODZDJZ9IvIrcnNY9CQqi03MxUNKeN6RKRsLo+lG7rLzV3F0g3dyOZCS88iIlKW0EAkn89j3rx5ePbZZ7Fp0yY0NzeL/HEUc9VVCSyZ3gLAtpcllkxvEZ6j4SVXhYgo7oQGInPnzkV7ezueeuop1NXVoa+vD319fTh69KjIH0sx1tbagFV3Xob6VPH1S32qFqvuvCyU3AzVclWIiFQmNFl11apVAICpU6cWff6JJ57A3XffLfJHU4y1tTbg+pZ6adUqKuWqEDnKZdn5laQSGoiE2KKEFCO7bLW6KhFaiW4pM1elL33Mbu4q6kPIVSFy1L0e6FgIZA6c+lyy0RjYx1k4FBLOmqHAxb1s1cxVmdPeiQSKh8CHmatCVFb3euCZu4DScDnTa3yeg/koJJy+S4Fi2apBhVwVIlu5rHESUq62q2OR8TgiwXgiQoFxKltNwChbvb6lPhanAbJzVYhs7X25+DpmmDyQ2W88jgP7SDAGIhQYFVusyyYzV4XI1vvvBPs4ogrwaoYCw7JVIk2MHhfs44gqwECEAsOyVSJNnHeVUR1Trg9xcrzxOCLBGIhQYFRpsU5EDqqqjRJdALZ9iNseYj8RCgUDEQqMKi3WiciFlhlGiW6ypIIr2cjSXQpVIq9w17FMJoNUKoV0Os0BeBqJex8RIq2wsyoJ4GX/ZiBCQsjurEpERPJ42b9ZvktCsGyViIjcYCBCRBRnvJohyRiIEBHFFYfekQJYNUNEFEfm0LvSVu/m0Lvu9XLWRbHDQISIKG449I4UwkBEIdlcHlt292Pd9v3Ysrsf2ZyyBU1EpDMvQ++IBGOOiCLYe4OIQsOhd6QQnogooKOrF3PaO4dNru1LH8Oc9k50dPVKWhkRRRKH3pFCGIhIls3lsXRDd7mbWizd0M1rGiIKDofekUIYiEi2refwsJOQofIAetPHsK3ncHiLIqJo49A7UggDEckODtgHIX4eR0TkCofekSKYrCrZ2XW1gT6OiMi1lhnAxGnsrEpSMRCRbHLzGDSkatGXPmaZJ5IAUJ8yhsYREQWuqhpo/pTsVVCM8WpGsuqqBJZMbwFge1OLJdNbOLlWcewBQ0TkD09EFNDW2oBVd142rI9IPfuIaIE9YIiI/Evk83ll37plMhmkUimk02kkk0nZyxEum8tjW89hHBw4hrPrjOsYnoSozewBU/p/IvNVW3XnZQxGiCh2vOzfPBFRSHVVAldOGCt7GZEjKsBz6gGTgNED5vqWegaUREQ2GIhQpIm8NvHSA4YBJhGFIpfVrgqKgQhFlt21idk6v9JrE/aAIaJABBU8dK83pioPHWiYbDSa1yncF4aBCEVSGNcm7AFD2tLwXXNkBRU8dK8HnrkLKP2vXqbX+LzCTepYvkuRFEbrfLMHTJlpHWhgDxhSTfd6YGUr8OTNwC/uNT6ubDU+T+Eyg4ehQQhwKnhw+5rkskYwU25qWcci43EKYiBCkRTGtQl7wJB2gtr4qHJBBg97Xx7+mpZ+v8x+43EKYiBCkRTWtYnZA6Y+Vfx96lO1LN0ltWj+rjlyggwe3n/H3c90+7iQMUeEIinM1vltrQ24vqWePWBIbV42PrZ8Fy/I4GH0OHffy+3jQsYTEYqkctcmgPH+70ufPDfQn3flhLG4ZdJ4XDlhLIMQUs9Ar7vHKfquOXKCDB7Ou8pIcC2XsZYcbzxOQQxEKLLsrk1MD//mP3DN8k3o6HL5H2giXXWvN65d3FD0XXPkBBk8VFUbVTbm15V+HwBoe0jZyigGIhRpba0NeGnhtfir6y60/HOzpwiDEYosM0H1g36HB6r9rjlygg4eWmYYJbrJkry0ZKPSpbsAc0QoJta8us/y82zFTpFWNkF1KPXfNUeSGTxY9hF5yHvw0DIDmDhNux4xDEQo8tiKnWLLMUH1pFFjgZsfPrXxseFZeIIOHqqqtUs2ZiBCkcdW7ArgxiaH28TTtmWnghBN24RrTcPgIUgMRCjy2IpdMm5s8rhNPK07mVegcZtw0heTVSnyvLRiz+by2LK7H+u278eW3f3I5pzu1qksdvKUy0tlBhue6SuXBXo2AzvWGh81e414IkKRZ/YUmdPeiQSK/zM7tBX7xu4+LN3QXZRP0pCqxZLpLeyQ6ofjxpYwNraJ03hNI4pZmfHMXYDdv34zQbVnMxue6SgCJ448EaFYcGrFDgBz2juHJbWyvLcCms+/iAy3ZZ2atwmPpYicOPJEhGLDrhU7AFyzfFO59+0s7/WDG5s6rCozmqYA+14xjvNHjwNGneXue7HhmRoidOLIQIRixWzFPtSW3f0s7xVB8/kXkTO0MqN7PfD9S4Yf5488Ezj6Hqw3t4TxGDY8U0OEZgcxEKHYY3mvIGaiZKYX3NgUUq4ypvA5h3wSki9CJ47MEaHYY3mvIJrPv4gkN8f5I8cAdfXFf6RBm/DYidCJI09EKPbM8t6+9DG79+2oT53KJzFlc/lh+SbMISkRdAtrqoyb4/yjh4G71gOJKjagU1mEThwZiFDsuS3vHRpkdHT1stTXLU3nX4QujO6zbo/pjxwCLrot2J9NwfJSmq04Xs0Qwbm8d2hw0dHVy1Jfr8xEyYtuMz5q8B/HUHWvB1a2Ak/eDPziXuPjytbgyy8jdJxP0Hri7lCJfD6vbOvITCaDVCqFdDqNZDIpezkUA07XLdlcHtcs32RbZWNe47y08Fpe05A7dsmj5rvaIDeUXNYIcJyO8+fvYLCoEwVnOXnZv3k1QzSEVXnvUJzkS4EKuxdEhI7zaQjNh+YJvZp58cUXMX36dDQ2NiKRSOBXv/qVyB8XSZx9ohaW+lKgZHSfjchxPkWH0BORI0eO4JJLLsGf/dmf4Qtf+ILIHxVJVgmRZ4w8DfdcfT7mXXshj/4lYKkvBUpWLwgmEJNChAYin/vc5/C5z31O5I+ILDMhsvT8472jJ/Dwb/4TT7y8Bw994SJWaITMb6kvkSWZyaNDj/MVzDGg+FCqamZwcBCZTKboVxxlc3ks3dBtudGZ3vvgBCs0JDBLfQHbFl3DSn2JbJm9IIb9azIlgOR4sb0gwqrYIbKhVCCybNkypFKpwq+mpibZS5LCKSHSlIcxjI15I+HyUupLVJbs7rPd64FnvqL99FbSW2jlu4lEAs8++yxmzpxp+5jBwUEMDg4Wfp/JZNDU1BS78t112/fj/jXbXT/+57OvYIWGBOysSoHpXm/RfXa82O6zuSzwvQnA0T/aPIClvOSftuW7NTU1qKmpkb0M6bwmOrJCQw6nUl8i12Qkj764okwQAug0vZX0plQgQgYzIdLN9QzACg2iSAizF0QuC7yyyt1jNZjeSnoTmiPy/vvvY/v27di+fTsAoKenB9u3b8fbb78t8sdqb2hCZDkJGPNNWKFBRJ7sfdnhNGQItnsnwYQGIv/6r/+KSy+9FJdeeikAYMGCBbj00kvx4IMPivyxkdDW2oBH77wMZ4w6zfLPWaFBJEkuC/RsBnasNT7msrJX5J3bU46RZ2oxvZX0JvRqZurUqVB4lI3y2lobcH1LPX6waRee+EMP3jt6ovBn9Zz0ShQ+y6TSRqPyxSmpVKVeHW5POabMYaIqCcehd5pghQaRZJUMp6skgBHBcfgdgJFjgP+9i4EI+eJl/1aqjwjZMys0bpk0HldOGMsghChMjsPpYAyns7qmMQMYWb06rK6SqqqBG5fBNghBApj+9wxCKBSsmiE6iadOZMvLcLqhlS9hT9ctZXcS03ob0LXW+mtE9y8hKsFAhAKj80ZuNWCwgXk4ZHKb3PnW88WBiN8AJgh2V0mZA8DL37f/uhu+wyCEQsVAhAKh80ZuN2CwL30Mc9o72bad3Cd3bv0RcO6VpzZyWdN1y57ElJMA/uUBoGU6r2WColKSsqKYI0IVMzfy0gZs5kau8mC+cgMGzc9xng85D6cbYmiuSJDTdb2UDTuexNgZckJDleNAQVcYiFBFdN/InQYM5gH0po9hW8/h8BblIJvLY8vufqzbvh9bdvcr+9xGSmE4nYvneuhGHtR0Xa8bWqUnLOymWjnZScoaYSBCFdFxIx/K7ZweVeb5dHT14prlm3DH41tx/5rtuOPxrbhm+SalT50io2UGcMVfuHusuZEHMV3Xz4ZWaTdUdlOtTCVVVjHEQIQqottGXsrtnB4V5vmUuwK7r70Tf7vhDZ6QiPbRm9w9buhG3jLD6DGSLMkzSjaW7z0C+N/QvFwlFXF5QkPleUlSJiarUmXC3siDrswxBwz2pY9Z/qc+AaOLrex5Pm6uwH7yhz34yR/2aJMkrCVzg7dtBJYw/rxpipHHYSYoTpzmb7qu36ob8yTmmbuMNblKWnV5QkPOZCUpa4qBCFUkzI1cRGWOOWBwTnvnsP9cqzTPx+kKbChW+whUdoM/+W+k9Vbg+5cE00W1kg3NPIkZ1kdkvLHGrrUWa2T/kEAEmaQcA2zxThUzrwwA6408iA3RrsQ2qJ+hevnxuu37cf+a7a4fbwaALy28VnoQFUmWjcJObvAvPwJfbeCt9Gw2ElOdzHrOvg+JXfkoy0rFcWyhf/LkbP6OyD7nXvZvBiIUCBEbuXkN05c5hm8+9wYOHzlh+bigNl2VG7Jt2d2POx7f6vnrfj77Clw5YayAFdGwjbxpyvCTkCI+Nh8ZGxoDlGAUGsoBlm/RvAalmvGyf/NqhgJhTgoOaiO3CmzsDK3MqWTTNef5qMjpCsyOqknCkVBVXXwK0bPZXT7HK48CU+5zt7lXVQM3LAPWzrL/njd+J7hAQbXhfDqzvRrjFVgpBiIUmKA2crtrGCdR3nTL5bKUo0K1T2y4zef45weALT9wt7l3rwf+ZbHD91sMJKqsv5eX0w3blvAny4Qj/g5eiJYZ/pKUY4blu6SUctUhTqK+6ba1NuDPP92MhItDpgSMqzHZ1T6x4iXx0E1TK7v+IW6/l5cmaOx7IY55cnbRbcZHBiHDMBAhpXipDjHFZdPt6OrF/32xB05tQlSq9okVT707HDZ3T7NiLL6X1yZo7HtBEjEQIaV4vV6Jy6br5aSoPlXL0l0ZynZRtVJmc/c8K2bI9/JzusG+FyQRc0RIKV6vV+pdVOaoXA3jltuTor+Z9jHcfXWz579fFJ6j0JTLu7BLUCzHanP3u+G//46/Jmjse0ESMRAhpbhpkDbm9BH4xrSPoT410nHDVL0/iFtuT4rOqqvxHEBE5TkKhZuqEjNB8ZVHjcRUJ1abu98Nf/Q4f6cbbjvGsvU7CcCrGRLOy7RYszoEsB0Rhm9/vhWfv+wcXDlhrGMQYjebZU57p1aD4kS10o/ScyScl7yLqmqjRNfv5F3Ps2KGfC8/pxtBDOcj8omBCAnlZ1psW2sDVt15GepTxZuql9wHN7NZlm7o1mZAnHlSVGZL85ywG7XnSCg/eReVbO6e8k1KvpdjEGMTAFUynI+oArG/muHduDh2/UDczEKptEGaU05FUE3QwiJiJk7UniOh/A6fq6Spld3XJqqAfM7+e7mZh2MXAHnte8EurBSAWAcivBsXx+nddgLGu+3rW+ptN89KGqS5zanQqQmaeVJU+m/WTcKulSg+R8JUOnzOb1Mrq69tmgLse6X896okACrtGGuHXVgpILENRCp5t07OZL/bFpVTIVuQrfSj+hwJUWlVidvN3e3XuvleIrt6sgsrBSiWgUgQ79apPNnvtt1U39Rr2gQtqFb6UX6OAqdrVUklAZAdt/kyE6fxmoZciWWyqpd36+SP7Hfbbqpvot4EzQmfIw9YVXKKm2Zr7MJKHsQyEJH9bl01Xspr3RJR5eFVENU3UcfnyANWlRjc5su89bzYdfiVyxqTknesNT5yfo50sbyakf1uXSWiEnZFVHn4EWRORVTxOfKA01Td58u8/gxw3VLnxNowRTnBVuMKpkQ+n1e2SUAmk0EqlUI6nUYymQzs+2ZzeVyzfJPj3fhLC6+N9H+M7RJ2zb9xEO+IWZlEpCm7jS2XBVZcCHzQ7/w9Ro0tfpzMTd8uwdZ0+5PAx2eGuaLgKBhgedm/YxmIAKc2YcD63XrUj6XNYMwuVybIYCxOvVpE/V3j9BySApw2to7FwNYf+fjGJ//Nhn2VlcsCK1vL57YkqoBbnwBaZ4a2rEDYBliSnuuTGIi4FOd361t29+OOx7c6Pu7ns69gMyuXRP17ivO/U5LAzcY28kzgyZt9/oCTFUbzd4R3ddCz2f16v/gzfa5pHAMsCc/1SV7271jmiJjifDceVsJuXN7Ji+pLw343FCrH0tyEUZr7v7afLGd2OWG49PtYdaEVycs0Y51Kj/12/FVMrAMRILieDLoJI2E3Lu/kRfWlYb8bCp3bjW3fK8BldwO//47/n+UlOKiUl2nGGmzcBZV0/FVILMt3Kfjy2tIS4Odfj89UV1F9aaLa70ZEuTgFxMvGNnZCZT+rf3dlX+9FYRCgS4pv3AWVdvxVROxPROIqyPJaq5OPqkTZvovav5MfeuX0n+8MuPoar9dcUex3E5dTMm2FubG9thr49NfDuQIpDAL8irvHK75xF+ja8bcEA5EYC2KIml0Og9Ob3N70MSxc+zo+9SdnVZw7EnYeitVm6obXa66o9bthvouNoPo/BPF9vG5sZR/rYOBAuFcgLTOMEt219xRPLy6ix8ZdUMmkZYUwEIm5ShJ2y+UwuLG287+wtvO/APh/Vxz2O2y7zbQcvzNbojQLhvkuNoLq/2D1feoagMvvMa5Q3AYmjicH+eKNzXYTdCnsK5CPzzSWuXaWxR/qs3EXqWTSsiKYI0KFhN1bJo3HlRPGut4InHIYvPCTO2IGBWHlofgJvCrpIhulWTBRzXepiFkmW5ocak6w7V5f2fcZ6DWSSX9xr1G6urLV/fd0y67t/aiz3H29jCuQ1plGiW5pzojOrfpbZgDzu4BZzwG3/tj4OH+HNn8XnohoSJWS2CBzE7y+K5bxDttP4OXlmstKENdnKtA230VU22y3ZbJOZaRlv08JM8Apt9kWvp8di3VZtb1vmgJ8/5Lwche8vk5RbNUvYtJySBiIaEalZL+gcxOGvit2Kqn28g47qPJst5vkvM9+BBeOGx1YkKhDvxun4FjLfBeRbbOD6v/gZhLu0O/pFOD4XZfVJhhW7oLf12nomjWe0xIFDEQ0olqyn1MOg19uNnxR77DLbahuN8mrP3JW4L1pVO534yY41i7fxa67qJtTBTeC6v/gOcfCIcAJsi9FGLkLQbxOCs5piRsGIppwexXxmT85G0+9shd7D3+A88aMwleuPB8jPiQmFcipBDgPIDXyQ0gf/W9P39fNhi/iHbbThqrdZhoCt8GxKtOYXQnq2qScoMpk/eZY2AUSQZfvirwCCeJ1Eh1wkitMVtWE26uIliUd+Oav38RPt+zFN3/9Jib+zT9h2fPdwtZl5jDUp4o3/PpULR698zIsv/ViJDA82dKKlyZqQTZky+by+Pvf/Afuc0h8jVLyaBCcgmPACI7NhmXl/q0oVbrr5XrCr0KDrTL/VkadZSSc9mw2Nl2/38eKXSDh+P0SQHK8t9wO8wrkotuMj26DkFzW+LvvWGv9HFT6OjkGMjACGbvnngLDExFNuL1iKB1hmMsDj73YAwBYfFNL0MsC4JzDYJVsWcrrRh7UO+yOrl78n/Xd6MtYr6008TUqyaNB8JOno0O+Syhts8v2fzjpg3eBX842/rfdVYGb71PEIUlUlb4Ubq5LKn2dIjKnJQoYiGii0iS+xzf34Gs3TBR6TWOXw1C6+ex59wh+vu1t9GUGC4/xs5FXGhS47QlSuqFqsZmGwG+ejsr5LgDC6y5ql0NhxeqqwEywzB4Hpi4GXnvCOEGx5TKQkN2Xwu11SaWvU0TmtEQBAxFNVJoYmssDP9uyB/d+6oLA1+ZG6eYz79oLCxv5WaNrgDzw7pFBbNnd72lT9xsU+OkJMnRDHfr3KU1wvfy8M/Ha3j9qEaRUUgquZSWMG2G2zR6aQzHQC3QsNk5ChinJedj5a+tAYeoDRgOz/t1A52r/gYSs8lYveR+Vvk4RmdMSBQxENFHuKsKtvYc/CHpZvpkbeUdXL77+j/9eUTmyn3fYfnqCWG2odnN2hra4V3WWSqWl4JFN3g37esLMoejZbBOEmE5eFby4Avj9MlieGPx+mXFiMHWhMcelkkBCRl8Kr9cllbxOEZnTEgVMVtWIXbJfXa27/7icN2aUiGX5FnZn1KG8lPXaJb7arb90zo4KE4dFTEeOdPKuXcdQkd033V4BvPIjuEqw9JskKpPX65JKXicz4ARg+y9Yt3bvmuKJiGasriImNZ2Bjy/pKDtorioBfOXK80NbpxPZs0e8XheUbqhernZkz1LxOh3Zy1qDTt61vCpCTk6zqbCvJ9xeARx9r8wfap5g6ee6pJLXSXY+DAGIaSCiSot0v6yuImZ/qrlQHWNl9qeahSWq+iGjM+pQbnNu6pM1+D8zPj5sQ/V6tSP672PHz3Rkr2sNKnnXKmD60ujtWHLaTzHyaN+pB4bZbCrM6wk3VwUjzwSOupjHo2uCpd/rEi+vU2kX1YnTotfuXTOxC0RUapFux0+gZJbmPr65p2iTqUoYQYio0l2/ZM8ecZNz81fX/QnmXfsRy+fe77rCnKVS6XRkL2uttBLGKmC6sWobvnNiJXACxSfnUW025SY3Zcp9xiA7J7omWJad/hvAdQm7qCopVoGIai3SrVQSKC2+qQVfu2EifrZlTyidVSuhQsWF3bWCm+fb77rCrCCpdDpyWGu1CpiqkMOS035q/O9hcWBA3U1V5HRVMHHayWqYiCdYjhwz/ORn5JnA9L/3HzBU0kWVs2iEik0gIjsnwY0gAqURH6qSVqLrheyKC/PUafC/c1hx+yWF8mG3J1Bey6nDriDJ5vL4w65Dvr427LVaBUyTq3aiMVHuCkLzXIhynHIeVGg4JopdsAAAR//o//tW0g6epyjChfJW+Yc//CHOP/981NbWYsqUKdi2bVsYP7aIl5wEGby2y9adzIqLjq5eXLN8E+54fCvuX7MdX/5/r+Dra/8dNR+qwpUTxnrq7Dp0veXkEV4Fifn3+8Hvdvv6+jyAL32yKdhFlWF1BXQ23nP3xbrmQjgpV/EiuqLHqbW6KGWDhZP8tlz32w7eDIxKv9Y8Rele730tNIzwQOTpp5/GggULsGTJEnR2duKSSy7BjTfeiIMHD4r+0UVk5yQ4UT1QEkHG7JEgS4bt1m8Vapwx6jQ/y/XM7u9nxy4uevg3/4lrlm8KpeTY6groIM5w98Vh50LI2qRLtcwA5ncBs54Dbv2x8XH+jsqDkO71wMpW4MmbgV/ca3xc2Spmwy19Lns2i5vx46eLKmfRhEb41czf/d3fYfbs2bjnnnsAAI8++ih+/etf4yc/+QkWLVok+scXqJCTUI7qgZIoYbZLF3E9N7x9/QdY+Zv/GPa49AcnhOcheUlONf92P7jjUvznwSN42GLNYeVOWV1zbctNxIH8GNTjsE2wJCEXQrUj+qAresKcRGv1XI48093X+jkF81MWzFk0oRF6InL8+HG89tpruO666079wKoqXHfdddiyZcuwxw8ODiKTyRT9CkqQ01pFUD1QEsmsuLhl0njXVyN+iDp1Mtd/88WNWPPq29Ku17wkp5qnTje2NmDNq29bPiasK0Gra64cqrD0xF3G/x72oyXkQkT9iD7Md/92z6XbHBA/p2B+pgpzFk1ohAYi7777LrLZLMaNK/6HM27cOPT19Q17/LJly5BKpQq/mpqCu6dWvQuk6oFSFIg+dZJ9veZ23fM++xG8tPBatLU2SF+zyeqa659zk/HAaX+NwVH1xQ8W2d3UShyO6P3mUHjlJg/ElkWw4JafLqqcRRMapapmFi9ejAULFhR+n8lkAg1GVB7hHtRYe7In+tRJ9vWa23Vf/ZGzCv+OZK95KOtruptQjUVySyfjcEQf1rt/x+fSTgCnYF67qHIWTWiEBiJnnXUWqqur8c47xf9433nnHdTX1w97fE1NDWpqakQuSekR7ioHSlEgumRY9vWan7+f7DWXsm6MJmH42lBxOKIP692/2+do5BnFreyDarnupR182MMPY0xoIDJixAhcfvnl+O1vf4uZM2cCAHK5HH77299i3rx5In90WZV2gRRJ5UBJd06nTmbZ6nOvH/D1vMvujeLnVE32mrUQhyP6sN79u32Obv8pkKgScwrmJcmXs2hCkcjn80IbUzz99NOYNWsWHnvsMUyePBkrV67EM888g507dw7LHSmVyWSQSqWQTqeRTCZFLpNixKp7rVle+94HJwqf89P63yyfBawDgaArUKzGAWzs7vPULTbsNWsnlzVKWJ026fk79H53XKiaASz/JQTVo0TH55KdVT3zsn8LD0QA4Ac/+AG+973voa+vD5MmTcL3v/99TJkyxfHrGIiQKEM3cLPktvT/CH434udfP4BvrOvC4SOVBTVOyo0D8HqqpsMMJqnC2KRlGbrJ9u8GXnsCGBjSPyY5Pth3/1F+LqlAuUDELwYiJFo2l8c1yzfZVo6YVxMvLbzW8Zomm8vjB5t24Yk/9OC9o6eCkDGnj8C3bmnFTRcHG4RYjQOo5BRD96nUwln2EQl4kw6bXW+Uy+4Gxk4Q9+4/is8lFWEgQuTSlt39uOPxrY6P+/nsK8rmFXV09WLRL3cUXe2Ygr7iCDJ4Io/CPqIX+fNs57qEdDLB645I87J/K1W+SxS2IMpXO7p6cd/JHAsrQQ9V9NL7Q9WkbG0F3c20HJGdXCsZAheUMJ9LUpp68+GJQlRp+arZVt1JkI3BVOr9QYKI7uQaVgMzIhcYiFCsVdrR1ktbdSCY4EC13h8UsDA6ucahNwppg4EIxVqlrf+9BhZBBAccBxBxYZxWVNIbRZUJxBQZDEQo9qzmnACnBsOVSzD1Elj4DQ6yuTy27O7Huu37sWV3PwAoPTeJKhTGaYWfIXCAcSW0shV48mbgF/caH1e26j/0j6RisiqVFZeSTr8dbZ06k5oS8BcclOvvwXEAERVGJ1c/7cvtqmzMvJWw+n/oXm2j+/oFYPku2WKTK3fsOpOazhx1GpZ94SLPz5mbXiEcBxBBYXYfddvPo7AmuysjizWJ2HDdVBKpvNGLrIRSDPuIUMVENMyKMsu28SNPwz1Xn495117oOThgr5CYC7P7qJuNu2ezcQ3jZNZzRkmuiA3XTd8TQN2N3mvfFpUDKhcYiFBForgJhnHFFOTPCKrRGmlMpe6jO9YaOSFObv0xUD0i+EZpbk5kRp4JHLUqj1egdbzXE6UInJywoRlVJGoNs8K6YgpyqjN7hZCnkfWiuc1HGXUWsG4OAm+U5qaSyDIIqfDnBsVLJdTRP6qRixMiVs3QMFHaBM0rptLAqi99DHPaO9HR1WvzlXKxVwgBONV99KLbjI+yjubdVtkkEmJKjyvuZyK5QZvb9Q/0iu8hoyAGIjRMVDZBs+tpmf9LY+mGbmRz6t1OsldIROnag8OssgFgWzTe9hBw5JC77+c1sKikQqiSnxsUt+s/ciiWHW8ZiNAwUdkEvVwxqabSRmukIN17cLTMMK4FkiXXmcnGU9cFokqPHU9kXAoqoPHK7YnS6R929/0i1vGWgQgNE5VNMOgrptLGYqJPUipptGYKe81kQ/TsmLC0zADmdxnVMbf+2Pg4f8epnAW/jdKcOJ7InExWDernBn1y5fZEqc5lzpqsgEoQJquSJXMT1LlhVpBXTLJ6qvhttCZzzVTC7ewYWYmUXpWbmuunUZpb5omMZTXJQ8b/DuLniqpYcVp/ywzj30qy0bmHjNdATnEs36WydO6sapYh23U9dVuGrGNPFR3XHFlee3CELbTGYwGVHpdbb6U/12uvj6DXX7QGQHgPGYHYR4ToJLuup243ZB17qui45kh7/Rngl7OdH/eFx4GLvyh+PUOJ7FchqyGX35/rp3usKCr1kPGJfUSITqr0iknHnio6rjnS3FaSuH1cUETPjil3hSOS35/rpdeH6L+XSj1kQsBAhCKvkjwLt4msfRl1eqpEqQ9MJLithHD7uCC4yVv5p4X65K0EIYypx17ICuQkYCBCseC366nbhNdvPvcGRp5WpUTeRVT6wADQft4GAPeVEG4fFwTHd/8ABg4AL64Api4MZ02yhTH1mCyxfJeoDKeeKqbDR04o06nVzZrHnj4Cl593Zmhr8kX3vhumQklrGX5KWivh9l3977+j3/Ptl6jSY3LEQIS0IaMnRrmeKlZU6NTqZs39R47jM9/7nRKBk6Wo9N0AhvSQKLPB+S1p9cvLu/oIthS35LbXR5ivk66deD1i1QxpQXZPjI6uXnz9H1/H+4P/7fhYVSbiWj1nQylbyqtS9UKQVKqEcHyOS8gqLZZBlddJ8wm8LN+lSFGhJ0Y2l8dlf/svSB9zDkT+/kuTcMuk8ULX49bx/87himW/weEjJyz/XMlSXtX7blRCpZyX7vXAM19x99hbf2wM3osL2a9TGP1MBPOyf/NqhpSmyuC6bT2HXQUhwKkkUBXaq7+294+2QQig6Lwd1aoXgqTKNF3A2MimPuDusXFL0JT5OrntxBuhaxpWzZDSVOmJ4bbU9YxRp2Fy8xjLa5Exp5+Gb93SipsudkhcDJCWpbyiqxdkv9tVyae/DnSudr4GY4JmeFTqZxISBiKkNFU2Urelrvdc1YyN3X2WV0mHj5zAXzz1b/jqf72HxTe1BL9IC1qW8prVCyLmbah67y4rOCqaDQMEOhuG/InyiaANXs1oToXjf5Fkb6Tm89uXOYYxp59W9rFnjDoNc6ZOsL1KMj32Yg+ef724WkXU6+hUypuAkfQ7uXlMID8vEKKqF1StxJFdpmwOY0uW5FklG7XIRYicGPYz4YmIxmRXkoTB3EidBteJ2Eidqk5KPfSFi/Da3j+6evzfrOvCja31qK5KCH0dzVLeOe2ddjNJsWR6izqJqiY3k0q9cLx3T8iZgCu6zbpbMWsprjSRJ4KK4omIpsxKktJNry99TJnGWkEo1xND5EZq9/xaaUjV4tGTlTtur4j6jxzHtp7DobyO5ryd+lTxqVF9qla90t2hWmYA87uM6phbf2x8nL/D38bs5d49LKolJaqUSBtnKvYzEYwnIhpyqiRJwKgkub6lXuo73Wwu72u+S6lKB9d5Ve75BYznd8zpI/CNaR9DfWpk0d/LyxVRX/oovvvPb4XyOlYyb0eqoOZtqHjv7icpkYm28RD0iaDiGIhoSJVKknKCvm4IcyN18/z2HzmO+tTIYc/v5OYxGHP6aWVLZk2HjxwP9XX0O28nElS8d/caHKmaaEtixOi6jFczGlKlksSOqOsGcyO9ZdJ4XDlhrLB385U8v9VVCXzrllbHr21I1WLM6JpA10NlqDhHxEtwpGqiLYkVk+syBiIakl1JUo4qDcgqUenze9PFjfjqp5ttvy4BI6+lPqnu66gNt7M4VLx3dxscNU1RK5eEKGAMRDSkckmml2sjVQXx/C6+qQU/+p+XYczpI4o+3zAkQVSl11HLMnCvZa+qlam6DY72vSIm0TYmA9VIfcwR0ZDKJZlhXxsFlRA7VFDP700XN+DGVvu8FlVeRy3LwP2Wvap27+4mKXHHWnffy0uibdTzTZjUqxUOvdOYihvIlt39uOPxrY6PC2JCrei/f1ht2mW+jioMFPQsitN5y22cQQ8BtB2odtLtTwIfn+l25eqJepClCU7fjRERJwKVruea5ZscG5BVOu01rA30+dd78Y11XTh85HjhcyKCBBmvo/la2V2lKTmZF4j2dF4rhcDLocGVm8DLMYgDkKgCbn0CaJ1ZwaIlicDU2qjg9N0YEVlJ4idvIIwGZGElxHZ09WLuU51FQQggpmlcWBVBQ2mbz6NiTxCRgky0dexdAiCfA9bO0q8SR7UGceQaAxGy1NHVi2uWb8Idj2/F/Wu2447Ht+Ka5Ztcbb6iO3mGsYFGofrHiepl4LZU7AkiWlCJtl6CM902bRW755IrTFalYeyuPcyTADfBhMgGZGFsoDo0jauUymXgZcVwFgeAYBJtvQRnuo2aj9tJWYQwEKEiQbaPF9XJM4wNVNvTAg9kDhSsSNHoept6o4jN4iiotOV9IYhzuJ4x6bRpx/GkLCJ4NUNFdMgbCKP/hranBR7IGigYCNV6guiiKN/EBZ02bRW755IrDESoiA4nAWFsoCo1GxNJ28m8QLDTeeOkZYZRopso959/DTdtFbvnkiu8mtFAmKWdupwEiJ7Iq0qzsTBoO5kXCG46ryiqNtb6+EzjH/XaWRZ/qPGmHbOptVHBPiKKC7vZVVh9QIIiOkhTsWkcaUKHxlqWaxyv/6atagAYI2xoFhGyul6aPxewPglQ/sg+YKo1jYsdHTcVnRpr6fj8kvIYiESA7K6XPAkgJehwqlAqii3oiTzysn8zR0RRsvtYaJ03QNHgd7CdbF4aa6mc30IUEgYiilKhekVUHxAiR47tuhNG58+J09Q7VWBjLSJPGIgoSpfqFZIn0rkrXk4VzrtKrRwHNtYi8oSBiKK07XpJoYh8Do/b04K3ngee/XO1ckji2oKeyCdhDc2+/e1v46qrrsKoUaNwxhlniPoxkaV110sSyqxqKs0hEjEVWBq3pwVbfzT85MTMIZE1PZaNtcTLZYGezcCOtcZHnYbz0TDCApHjx4/j9ttvx5w5c0T9iMjTuuslCRGHqcAAXLTrRpnOoAqMfGcLenG61xtVSU/eDPziXuPjylZ5gSdVTHj57urVqzF//ny89957nr82zuW7Q0U6F4A82bK7H3c8vtXxcT+ffYX+icaFqhlgeEcbl//ZmvWc3MoU9ugIlk79WWJO2/LdwcFBDA4OFn6fyWQkrkYdrF5xL+pBmwrVVKEp16675RbjWsaJ7MoU1VvQ60TnSioqS6lAZNmyZVi6dKnsZcSazht55BM4EcNqqpYZxsZSeqqw92V3gQgrU6Ij7P4sPM0KjadAZNGiRVi+vPwI6TfffBMTJ070tZjFixdjwYIFhd9nMhk0NTX5+l7knc4buV07fDOBMyo5NbGsprI6VWBlSvyE2Z9Fx46+GvOUrPq1r30Nb775ZtlfF1xwge/F1NTUIJlMFv2icOhciRGbBE6wmqqAlSnxE1Z/FjMPRbVqrAjzdCLy4Q9/GB/+8IdFrYUkcdrIEzA28utb6pXc4GS3ww+bWU1VenpVr8npVWA48j1ewjgFYx6KFMJyRN5++20cPnwYb7/9NrLZLLZv3w4A+MhHPoLRo0eL+rGxVGleh+4beawSOE/iLKCT7HJIuEmEJ6xcCvMU7Jm7MLxyKqBTMM4JkkJYIPLggw/iySefLPz+0ksvBQD87ne/w9SpU0X92NgJIq9D9408dgmcJ7GaCkwolC3sXArRp2CcEySFsEBk9erVWL16tahvTwguQVP3jTyWCZzEhELZZE1HNk/BejYDe18yfnzzp4Dzr6n8e3NOkBTCOquSWEEmaJobud2hfgLGKYuqGzkTOGOICYVyOeZSQGxn252/BtbNAV78HrD5e8BPZwTTXdWxo28CSI5nNVbAGIhoykteh5MobORshx8jsjdB8pZLETSRQSirsaRQqqEZuRd0XoddJcaZp5+Gb93SqsVG7jeBU+cmbrHEhEL5ZOVShFHVwmqs0DEQ0ZSIvI621gbkcsA31nXh8JHjAIDDR07gm79+E1VVCS2CEa8JnDo3cYstJhR6F3RSr6xcirCCUFZjhYqBiKZEJGh2dPVi7lPWya/3tXfiz64+H9e31EfmxCAu3VgjhwmF3ohI6pXV2TbMIJRzgkLDHBFNBZ3X4Sb59Sd/2IM7Ht+Ka5ZvUrrTqhtx6sZaVi5rVB/sWGt81CGvggmF7onKp5CVS8EgNJIYiGgsyARNp+TXoXRo++4kyGRfbXWvNyoNnrwZ+MW9xscgKg9EY0KhO6KTes1cimTJf2eSjeJKd8MIQnUMzjXHqxnNBdFhM5vL4w+73nX9eB3avjvRvYlbxWT1gAgKEwqdhZFPEXYuhejuquxNIwUDkQiopMOmVbKmG6q3fXeiexO3ikRlngYTCssLK58i7FwKUUGo7sG5xhiIxJhdsqYXup4YxLoba5TKX5lQaC/K+RRBB6FRCc41xRyRmCqXrOmFricGUWji5hvLX+NBVD6FKjkUZhB60W3Gx7CG3VHgGIjElJfkVCuqt313I7bdWKP8TplOEZHUq2uCsxMG51LxaiYC/HQGreRKJUonBkEk+2pHVg8ICl+Q+RRRzqFgcC4VAxHN+e0MuufdD1x9/7+67k+w5tW3i75/fcQ6j1aS7Ksl0ZUHpJYg8iminkPB4FyqRD6fV7ZjUyaTQSqVQjqdRjKZlL0c5dglm5rv5e2uF7K5PK5+aBP6MuVPReqTNfjDov8BAMJPDDjvRQLLUsXxLH+l4Xo2G9cwTmY9p2/ycOHEB7AMznU+8ZHAy/7NExFNOXUGLdfnY1vPYccgBADumHxu4WtFnhhw3oskLH8lt+KQQ8HeNNIwENGUl86gpUGE2/yQ8886vZIlusJ5L5Kx/JXciEsOBYNzKRiIaKqSzqCqNPOq5FTH/Hpe5xCFIE45FAzOQ8dARCNDN953BwZdfY1VMKFKM69KTnV4nUMUIiY4k0AMRDRhtfFWJQC74bDlggmzmdec9k67/6SEUprr91SH1zlEEjCHggRhIKIBu423XBAClA8mzGZepcFNmKW5fq6I/Fzn8AqHKCDMoSABGIgozk0r9tKTEbfBhOxmXn6uiLxe5/AKhyhgzKGggDEQUZybVuy5PPA30z6Gs+pqPAcTMpt5+bki8nKdwyscogDksjwBIaEYiCjO7cZ7Vl0Nbpk0XvBqguf1isjtdc5Zp9fg62v/3XdFDhHBpuldo5G4ypwQCggDEcWpUmorkpcrIrfXOUjAd0UOESHas2XIoMhpFwMRxalSaiua2ysit9c5777vrry5kuF/RIFRZEMoWk+UZ8uQUqddVaH+NPLM3HgB20HekZiC64V5nVOfKj4Fqk/VFvI+4nCSRBHRvR5Y2WrMcvnFvcbHla3G52XZ+3LxBjVMHsjsNx5H+jFPu0pfY/O0K+R/ezwR0YAKpbaqcbrOictJEmlO1euPOMyWiSsFT7sYiGhCdqltUILs6VHuOkeVpm1EthTcEAriMlsmjrycdoVUps1ARCMyS22DEHZPD54kkdIU3BAK4jRbJm4UPO1iIEKhkNXTIyonSRRBCm4IBZwtE10KnnYxWZWEc2rLDhg9PbJ2PesrZJ4k3TJpPK6cMJZBCKlBwQ2hiDlbJlnyBiHZyNJdnZmnXcPKH0wJIDk+1NMunoiQcJVM2SWKLB2uPzhbJnoUPO3iiQgJ53fKLlGkmRsCANvifBWuP8zZMhfdZnyUvR6qnGKnXTwRIeHY04PIhrkhWDaWeojXHySOQqddDERIOPb0ICpDoQ2BYkaRScq8miHh2B2WyAGvPyjGGIhQKNy0ZSciioVcFujZDOxYa3zMZWWvSCpezVBo2NODiGJPoWFzqmAgQqHSvTusW0G2sieiiFB1tpBkDESIAuanlT0DF6KIU3m2kGQMRIgC5KeVfdgzeIhClcuyIghQe7aQZAxEiALi1Mo+AaOV/fUt9YXTDlkzeIhCwXyIU1SeLSQZq2aIAuKllT0gfwYPkVBmPkTpKYCZD9G9Xs66ZFF9tpBEDESIAuK1lb3XwIVIG475EDDyIeJUtqrgsDlVMBAhCojXVvacwUOR5SUfIi50mS0kAQMR8iWby2PL7n6s274fW3b38/oAp1rZl3m/g4Yhrew5g4cii/kQ1hQbNqcKJquSZ6zysGa2sp/T3mk3XLuolT1n8FBkMR/CHmcLDcMTEfLErPIozW0wqzw6unolrUwNXlrZcwYPRRbzIcrjbKEiiXw+r+yZeiaTQSqVQjqdRjKZlL2c2Mvm8rhm+SbbBEvzHfxLC6+N/ebppUEZT5gokgpdRAHL88EYX0XEgZf9m1cz5JqXKo84tHEvx0sre87goUgy8yEs+4g8xCCEChiIkGus8hAnLjN4SBJZ3U2ZD0EuMBAh11jlQaQh2d1NzXwIIhtMViXXvJanEpFk7G5KGhAWiOzZswf33nsvmpubMXLkSEyYMAFLlizB8ePHRf1IEoxVHkQaYXdT0oSwQGTnzp3I5XJ47LHH8MYbb+Dhhx/Go48+igceeEDUj6QQeClPJSKJ2N2UNCEsR6StrQ1tbW2F319wwQV46623sGrVKqxYsULUj6UQsMqDSAPsbkqaCDVZNZ1OY8wY+/yBwcFBDA4OFn6fyWTCWBb5wCoPIsWxuylpIrRk1V27duGRRx7BV7/6VdvHLFu2DKlUqvCrqakprOUREUULu5uSJjwHIosWLUIikSj7a+fOnUVfs3//frS1teH222/H7Nmzbb/34sWLkU6nC7/27dvn/W9EpCAOCaTQcdoracJzi/dDhw6hv7+/7GMuuOACjBgxAgBw4MABTJ06FVdccQVWr16Nqir3sQ9bvFMUsIU7SWXZR2Q8u5uSUF72b6GzZvbv34/PfvazuPzyy9He3o7qam+RNwMR0p05JLD0/2Tm+1NWGlEoZHVWpdjysn8LyxHZv38/pk6dinPPPRcrVqzAoUOH0NfXh76+PlE/kkgp2VweSzd0l+vigKUbunlNQ+KZ3U0//nnj9288C/RsZg8RUoKwqpmNGzdi165d2LVrF84555yiP1N44C9RYDgkkJQiu9U7kQ1hJyJ333038vm85S+iOOCQQGdM4g0JW72Twjj0jkgQDgksj0m8IXFs9Z4wWr1PnKZP3ghzXiKFgQiRIOaQwL70McstIAGjNX4chwTaJfH2pY9hTnsnk3iD5KXVuw5TcnnFFDmcvktURiVXBxwSaI1JvCGLUqt3XjFFEk9EiGwEcXVgDgks/T71Mb6CYBJvyKLS6j2KV0wEgIEIkaUgrw44JLAYk3hDZrZ6z/TCehNPGH+ueqv3qF0xUQGvZohKiLg6MIcE3jJpPK6cMDa2QQjAJN7QRaXVe5SumKgIAxGiEl6uDioVx/JVM4m3zCg2NMQ0iVeYlhnAF38KJEtO8ZKNxud1SPKMyhUTDcOrGaISYV0dxLV81UzindPeiQSKLwvinMQrXMsMI39C17LXqFwx0TA8ESEqEcbVgZmDUnryYuagdHT1+v7eOjCTeOtTxc9hfaqWpbsima3eL7rN+KhLEAJE54qJhuGJCFEJ0f0/nHJQEjByUK5vqfd9KpDN5ZVPjmUSL3lmXjFZ9hHhNGFdMRAhKiH66kB0+apOVz5mEi+Ra7pfMdEwvJohsiDy6kBkDkrcr3woJnS+YqJheCJCZEPU1YGoHJQwrnyIiILGQISoDBFXB6JyUNixlIh0xKsZopCJmkHDjqVEpCMGIkQSiMhBYcdSItIRr2aIJAk6B0V02TERkQgMRIgkCjIHhR1LiUhHvJohihB2LCUi3fBEhChi2LGUiHTCQIQogtixlIh0wasZIiIikoaBCBEREUnDqxkiIplyWQ5wo1hjIEJEJEv3epuR9ss50p5ig1czREQydK8HnrmrOAgBgEyv8fnu9XLWRRQyBiJERGHLZY2TENtZyQA6FhmPI4o4BiJERGHb+/Lwk5AieSCz33gcUcQxECEiCtv77wT7OCKNMRAhIgrb6HHBPo5IYwxEiIjCdt5VRnUM7NruJ4DkeONxRBHHQISIKGxV1UaJLoDhwcjJ37c9xH4iFAsMRIiIZGiZAXzxp0CyZCJystH4PPuIUEywoRkRkSwtM4CJ09hZlWKNgQgRkUxV1UDzp2SvgkgaXs0QERGRNAxEiIiISBoGIkRERCQNAxEiIiKShoEIERERScNAhIiIiKRhIEJERETSMBAhIiIiaRiIEBERkTRKd1bN5/MAgEwmI3klRERE5Ja5b5v7eDlKByIDAwMAgKamJskrISIiIq8GBgaQSqXKPiaRdxOuSJLL5XDgwAHU1dUhkSgdla2OTCaDpqYm7Nu3D8lkUvZyaAi+Nuria6MuvjZq0ul1yefzGBgYQGNjI6qqymeBKH0iUlVVhXPOOUf2MlxLJpPK/+OIK7426uJroy6+NmrS5XVxOgkxMVmViIiIpGEgQkRERNIwEAlATU0NlixZgpqaGtlLoRJ8bdTF10ZdfG3UFNXXRelkVSIiIoo2nogQERGRNAxEiIiISBoGIkRERCQNAxEiIiKShoGIIIODg5g0aRISiQS2b98uezmxt2fPHtx7771obm7GyJEjMWHCBCxZsgTHjx+XvbRY+uEPf4jzzz8ftbW1mDJlCrZt2yZ7SbG3bNkyfPKTn0RdXR3OPvtszJw5E2+99ZbsZZGFhx56CIlEAvPnz5e9lEAwEBHkr//6r9HY2Ch7GXTSzp07kcvl8Nhjj+GNN97Aww8/jEcffRQPPPCA7KXFztNPP40FCxZgyZIl6OzsxCWXXIIbb7wRBw8elL20WHvhhRcwd+5cbN26FRs3bsSJEydwww034MiRI7KXRkO8+uqreOyxx3DxxRfLXkpw8hS4559/Pj9x4sT8G2+8kQeQ/7d/+zfZSyIL3/3ud/PNzc2ylxE7kydPzs+dO7fw+2w2m29sbMwvW7ZM4qqo1MGDB/MA8i+88ILspdBJAwMD+QsvvDC/cePG/Gc+85n8/fffL3tJgeCJSMDeeecdzJ49Gz/72c8watQo2cuhMtLpNMaMGSN7GbFy/PhxvPbaa7juuusKn6uqqsJ1112HLVu2SFwZlUqn0wDA/48oZO7cuZg2bVrR/3+iQOmhd7rJ5/O4++67cd999+ETn/gE9uzZI3tJZGPXrl145JFHsGLFCtlLiZV3330X2WwW48aNK/r8uHHjsHPnTkmrolK5XA7z58/H1VdfjdbWVtnLIQBr1qxBZ2cnXn31VdlLCRxPRFxYtGgREolE2V87d+7EI488goGBASxevFj2kmPD7Wsz1P79+9HW1obbb78ds2fPlrRyInXNnTsXXV1dWLNmjeylEIB9+/bh/vvvxz/8wz+gtrZW9nICxxbvLhw6dAj9/f1lH3PBBRfgi1/8IjZs2IBEIlH4fDabRXV1Nb785S/jySefFL3U2HH72owYMQIAcODAAUydOhVXXHEFVq9ejaoqxuJhOn78OEaNGoW1a9di5syZhc/PmjUL7733HtatWydvcQQAmDdvHtatW4cXX3wRzc3NspdDAH71q1/h85//PKqrqwufy2azSCQSqKqqwuDgYNGf6YaBSIDefvttZDKZwu8PHDiAG2+8EWvXrsWUKVNwzjnnSFwd7d+/H5/97Gdx+eWXo729Xev/4+psypQpmDx5Mh555BEAxjXAueeei3nz5mHRokWSVxdf+Xwef/mXf4lnn30Wv//973HhhRfKXhKdNDAwgL179xZ97p577sHEiROxcOFC7a/PmCMSoHPPPbfo96NHjwYATJgwgUGIZPv378fUqVNx3nnnYcWKFTh06FDhz+rr6yWuLH4WLFiAWbNm4ROf+AQmT56MlStX4siRI7jnnntkLy3W5s6di6eeegrr1q1DXV0d+vr6AACpVAojR46UvLp4q6urGxZsnH766Rg7dqz2QQjAQIRiYuPGjdi1axd27do1LCjkoWC4/vRP/xSHDh3Cgw8+iL6+PkyaNAkdHR3DElgpXKtWrQIATJ06tejzTzzxBO6+++7wF0SxwasZIiIikoaZekRERCQNAxEiIiKShoEIERERScNAhIiIiKRhIEJERETSMBAhIiIiaRiIEBERkTQMRIiIiEgaBiJEREQkDQMRIiIikoaBCBEREUnDQISIiIik+f+YPNYHHwT8ggAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cluster1 = np.random.normal(0, 1, (100, 2)) - (2, 0)\n",
    "cluster2 = np.random.normal(0, 1, (100, 2)) + (2, 0)\n",
    "\n",
    "plt.scatter(cluster1[:, 0], cluster1[:, 1])\n",
    "plt.scatter(cluster2[:, 0], cluster2[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = dl.MultiLayerPerceptron(2, [10], 1, out_activation=nn.Sigmoid)\n",
    "classifier = dl.BinaryClassifier(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ loss          │ CrossEntropyLoss │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ train_metrics │ MetricCollection │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ val_metrics   │ MetricCollection │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ test_metrics  │ MetricCollection │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ classifier    │ BinaryClassifier │     41 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ optimizer     │ Adam             │      0 │\n",
       "└───┴───────────────┴──────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ loss          │ CrossEntropyLoss │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ train_metrics │ MetricCollection │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ val_metrics   │ MetricCollection │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ test_metrics  │ MetricCollection │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ classifier    │ BinaryClassifier │     41 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ optimizer     │ Adam             │      0 │\n",
       "└───┴───────────────┴──────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 41                                                                                               \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 41                                                                                                   \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 41                                                                                               \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 41                                                                                                   \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eff27c690ad4de2acba23c72aa517fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\bmidt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:104: \n",
       "Total length of `list` across ranks is zero. Please make sure this was your intention.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\bmidt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:104: \n",
       "Total length of `list` across ranks is zero. Please make sure this was your intention.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bmidt\\DeepTorch\\docs3.ipynb Cell 58\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bmidt/DeepTorch/docs3.ipynb#Y105sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bmidt/DeepTorch/docs3.ipynb#Y105sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     trainer \u001b[39m=\u001b[39m dl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bmidt/DeepTorch/docs3.ipynb#Y105sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     trainer\u001b[39m.\u001b[39;49mfit(al_model)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bmidt/DeepTorch/docs3.ipynb#Y105sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m# Update the dataset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bmidt/DeepTorch/docs3.ipynb#Y105sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     al_model\u001b[39m.\u001b[39mquery_and_update(\u001b[39m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bmidt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[0;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[0;32m    545\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[0;32m    546\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bmidt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\bmidt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    574\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    575\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[0;32m    576\u001b[0m     ckpt_path,\n\u001b[0;32m    577\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    578\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    579\u001b[0m )\n\u001b[1;32m--> 580\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49mckpt_path)\n\u001b[0;32m    582\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[0;32m    583\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bmidt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:989\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    986\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    987\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[0;32m    991\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    992\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m    994\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bmidt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1033\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m   1032\u001b[0m     \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[1;32m-> 1033\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[0;32m   1034\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m   1035\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[1;32mc:\\Users\\bmidt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1064\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m val_loop\u001b[39m.\u001b[39mrun()\n\u001b[1;32m-> 1064\u001b[0m call\u001b[39m.\u001b[39;49m_call_callback_hooks(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mon_sanity_check_end\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   1066\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39mreset_results()\n",
      "File \u001b[1;32mc:\\Users\\bmidt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:208\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[1;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[39mif\u001b[39;00m callable(fn):\n\u001b[0;32m    207\u001b[0m         \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Callback]\u001b[39m\u001b[39m{\u001b[39;00mcallback\u001b[39m.\u001b[39mstate_key\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 208\u001b[0m             fn(trainer, trainer\u001b[39m.\u001b[39mlightning_module, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m pl_module:\n\u001b[0;32m    211\u001b[0m     \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\bmidt\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\callbacks\\progress\\rich_progress.py:380\u001b[0m, in \u001b[0;36mRichProgressBar.on_sanity_check_end\u001b[1;34m(self, trainer, pl_module)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_sanity_check_end\u001b[39m(\u001b[39mself\u001b[39m, trainer: \u001b[39m\"\u001b[39m\u001b[39mpl.Trainer\u001b[39m\u001b[39m\"\u001b[39m, pl_module: \u001b[39m\"\u001b[39m\u001b[39mpl.LightningModule\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    379\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_sanity_progress_bar_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    381\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_sanity_progress_bar_id, advance\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, visible\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefresh()\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import deeplay.activelearning as al\n",
    "# Creating an active learning dataset\n",
    "\n",
    "torch_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(np.vstack([cluster1, cluster2]), dtype=torch.float32),\n",
    "    torch.tensor([0] * 100 + [1] * 100, dtype=torch.float32)\n",
    ")\n",
    "dataset = al.ActiveLearningDataset(torch_dataset)\n",
    "\n",
    "# Creating an active learning model\n",
    "al_model = al.UncertaintyStrategy(classifier, criterion=al.Entropy(), train_pool=dataset, batch_size=8).build()\n",
    "\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset.annotate_random(16)\n",
    "\n",
    "\n",
    "for iter in range(10):\n",
    "    trainer = dl.Trainer(max_epochs=10)\n",
    "    trainer.fit(al_model)\n",
    "\n",
    "    # Update the dataset\n",
    "    al_model.query_and_update(10)\n",
    "    al_model.reset_model()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
