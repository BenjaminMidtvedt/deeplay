{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeptorch as dtm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "mnist = torchvision.datasets.MNIST(\n",
    "    root=\"data\", train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "\n",
    "mnist_test = torchvision.datasets.MNIST(\n",
    "    root=\"data\", train=False, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataloader = torch.utils.data.DataLoader(mnist, batch_size=32, num_workers=4)\n",
    "mnist_test_dataloader = torch.utils.data.DataLoader(mnist_test, batch_size=32, num_workers=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using default ImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (val_accuracy): MulticlassAccuracy()\n",
       "  (test_accuracy): MulticlassAccuracy()\n",
       "  (classifier): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=576, out_features=128, bias=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=10, bias=True)\n",
       "      (1): Softmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = dtm.ImageClassifier(num_classes=10).build((1, 1, 28, 28))\n",
    "\n",
    "classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways to modify the classifier\n",
    "\n",
    "The following are a few ways to modify the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (val_accuracy): MulticlassAccuracy()\n",
       "  (test_accuracy): MulticlassAccuracy()\n",
       "  (classifier): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=288, out_features=128, bias=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=10, bias=True)\n",
       "      (1): Softmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = dtm.ImageClassifier(\n",
    "    num_classes=10,\n",
    "    backbone=dict(\n",
    "        channels_out=[8, 16, 32]\n",
    "    ),\n",
    "        \n",
    ")\n",
    "classifier.build((1, 1, 28, 28))\n",
    "\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (val_accuracy): MulticlassAccuracy()\n",
       "  (test_accuracy): MulticlassAccuracy()\n",
       "  (classifier): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Flatten(start_dim=1, end_dim=-1)\n",
       "      (1): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=10, bias=True)\n",
       "      (1): Softmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks = [\n",
    "    dtm.ConvPoolBlock(\n",
    "        channels_out=16,\n",
    "        conv=dtm.ConvActNormBlock(channels_out=16, conv=dict(padding=0))\n",
    "    ),\n",
    "    dtm.ConvPoolBlock(\n",
    "        channels_out=32,\n",
    "        conv=dtm.ConvActNormBlock(channels_out=32, conv=dict(padding=0))\n",
    "    ),\n",
    "    dtm.ConvPoolBlock(\n",
    "        channels_out=64,\n",
    "        conv=dtm.ConvActBlock(channels_out=64, conv=dict(padding=0))\n",
    "    )\n",
    "]\n",
    "\n",
    "classifier = dtm.ImageClassifier(\n",
    "    num_classes=10,\n",
    "    backbone=dict(\n",
    "        blocks=blocks\n",
    "    ),\n",
    "        \n",
    ")\n",
    "classifier.build((1, 1, 28, 28))\n",
    "\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassifier(\n",
       "  (val_accuracy): MulticlassAccuracy()\n",
       "  (test_accuracy): MulticlassAccuracy()\n",
       "  (classifier): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=10, bias=True)\n",
       "      (1): Softmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class GlobalAvgPoolConnector(dtm.LazyModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def build(self, *args):\n",
    "        return nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(32),\n",
    "            nn.ReLU(),\n",
    "            nn.LazyLinear(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "blocks = [\n",
    "    dtm.ConvPoolBlock(\n",
    "        channels_out=16,\n",
    "        conv=dtm.ConvActNormBlock(channels_out=16, conv=dict(padding=0))\n",
    "    ),\n",
    "    dtm.ConvPoolBlock(\n",
    "        channels_out=32,\n",
    "        conv=dtm.ConvActNormBlock(channels_out=32, conv=dict(padding=0))\n",
    "    ),\n",
    "    dtm.ConvActBlock(\n",
    "        channels_out=64,\n",
    "        conv=dtm.ConvActBlock(channels_out=64, conv=dict(padding=0))\n",
    "    )\n",
    "]\n",
    "\n",
    "backbone = dtm.Encoder2d(\n",
    "    blocks=blocks\n",
    ")\n",
    "\n",
    "\n",
    "classifier = dtm.ImageClassifier(\n",
    "    num_classes=10,\n",
    "    backbone=backbone,\n",
    "    connector=GlobalAvgPoolConnector()\n",
    ")\n",
    "classifier.build((1, 1, 28, 28))\n",
    "\n",
    "classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "1 | test_accuracy | MulticlassAccuracy | 0     \n",
      "2 | classifier    | Sequential         | 26.9 K\n",
      "-----------------------------------------------------\n",
      "26.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "26.9 K    Total params\n",
      "0.107     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cb57f8285543c1a45941f4bb159e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e61a950621e4b05a173644d544689fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e530a7cd1c24b34a6aa23a8c48e5287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e3ba592605745e29b4be2c20253f43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cb625c93bb44a995588e2106708b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e4675d7e704313b91781c9c3577c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aeac400511646498010f5bda2369c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=5, accelerator=\"cuda\")\n",
    "trainer.fit(classifier, mnist_dataloader, mnist_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GU\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\checkpoint_connector.py:134: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at c:\\Users\\GU\\DeepTorch\\examples\\vision\\classification\\lightning_logs\\version_6\\checkpoints\\epoch=4-step=9375.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at c:\\Users\\GU\\DeepTorch\\examples\\vision\\classification\\lightning_logs\\version_6\\checkpoints\\epoch=4-step=9375.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf5c5942372467b828cda40c757a65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9815999865531921     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.479982614517212     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9815999865531921    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.479982614517212    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.9815999865531921, 'test_loss': 1.479982614517212}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(dataloaders=mnist_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\GU\\DeepTorch\\examples\\vision\\classification\\MNIST_Classifier.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# config = dtm.Config()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# config.set()\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mEncoder\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     defaults \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlayers.module\u001b[39m\u001b[39m\"\u001b[39m: nn\u001b[39m.\u001b[39mConv2d,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlayers.channels_out\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m i: \u001b[39m8\u001b[39m \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m i,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpools.stride\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, depth\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, layers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, activations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalizations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pools\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[1;32mc:\\Users\\GU\\DeepTorch\\examples\\vision\\classification\\MNIST_Classifier.ipynb Cell 14\u001b[0m in \u001b[0;36mEncoder\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mEncoder\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     defaults \u001b[39m=\u001b[39m {\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlayers.module\u001b[39m\u001b[39m\"\u001b[39m: nn\u001b[39m.\u001b[39mConv2d,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlayers.channels_out\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlambda\u001b[39;00m i: \u001b[39m8\u001b[39m \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m i,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlayers.kernel_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m3\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlayers.padding\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mactivations.module\u001b[39m\u001b[39m\"\u001b[39m: nn\u001b[39m.\u001b[39mReLU,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnormalizations.module\u001b[39m\u001b[39m\"\u001b[39m: nn\u001b[39m.\u001b[39mBatchNorm2d,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpools.module\u001b[39m\u001b[39m\"\u001b[39m: nn\u001b[39m.\u001b[39mMaxPool2d,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpools.kernel_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpools.stride\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m2\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, depth\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, layers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, activations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalizations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pools\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m        Parameters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m        ----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m            Normalization config for each layer in the encoder.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/GU/DeepTorch/examples/vision/classification/MNIST_Classifier.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m                \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# config = dtm.Config()\n",
    "# config.set()\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    depth : int, optional\n",
    "        Number of layers in the encoder.\n",
    "    layers : dict, LayerConfig, optional\n",
    "        Layer config for each layer in the encoder.\n",
    "    activations : dict, LayerConfig, optional\n",
    "        Activation config for each layer in the encoder.\n",
    "    normalizations : dict, LayerConfig, optional\n",
    "        Normalization config for each layer in the encoder.\n",
    "            \"\"\"\n",
    "\n",
    "    defaults = {\n",
    "        \"layers.module\": nn.Conv2d,\n",
    "        \"layers.channels_out\": lambda i: 8 * 2 ** i,\n",
    "        \"layers.kernel_size\": 3,\n",
    "        \"layers.padding\": 1,\n",
    "        \"activations.module\": nn.ReLU,\n",
    "        \"normalizations.module\": nn.BatchNorm2d,\n",
    "        \"pools.module\": nn.MaxPool2d,\n",
    "        \"pools.kernel_size\": 2,\n",
    "        \"pools.stride\": 2,\n",
    "    }\n",
    "\n",
    "    def __init__(self, depth=4, layers=None, activations=None, normalizations=None, pools=None):\n",
    "\n",
    "        super().__init__(depth=depth, layers=layers, activations=activations, normalizations=normalizations, pools=pools)\n",
    "        \n",
    "        self.depth = self.request(\"depth\")\n",
    "        self.layers = [self.request(\"layer\", i) for i in range(self.depth)]\n",
    "        self.activations = [self.request(\"activation\", i) for i in range(self.depth)]\n",
    "        self.normalizations = [self.request(\"normalization\", i) for i in range(self.depth)]\n",
    "        self.pools = [self.request(\"pool\", i) for i in range(self.depth)]\n",
    "\n",
    "    def forward(self, x): \n",
    "        for i in range(self.depth):\n",
    "            x = self.layers[i](x)\n",
    "            x = self.normalizations[i](x)\n",
    "            x = self.activations[i](x)\n",
    "            x = self.pools[i](x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Syntax 1\n",
    "model = Encoder(\n",
    "    depth=3,\n",
    "    layers=dtm.Config()\n",
    "            .channels_out(lambda i: 4 * 2 ** i)\n",
    "            .kernel_size(3),\n",
    "    activations=dtm.Config()\n",
    "            .module(nn.LeakyReLU)\n",
    "            .inplace(True),\n",
    ")\n",
    "\n",
    "# Syntax 2\n",
    "model = Encoder(\n",
    "    depth=3,\n",
    "    **dtm.Config()\n",
    "        .layers.channels_out(lambda i: 4 * 2 ** i)\n",
    "        .layers.kernel_size(3)\n",
    "        .activations.module(nn.LeakyReLU)\n",
    "        .activations.inplace(True)\n",
    ")\n",
    "\n",
    "# Syntax 3\n",
    "model = Encoder(\n",
    "    **dtm.Config()\n",
    "        .depth(3)\n",
    "        .layers.channels_out(lambda i: 4 * 2 ** i)\n",
    "        .layers.kernel_size(3)\n",
    "        .activations.module(nn.LeakyReLU)\n",
    "        .activations.inplace(True)\n",
    ")\n",
    "\n",
    "# Syntax 4\n",
    "model = Encoder(\n",
    "    **{\n",
    "        \"depth\": 3,\n",
    "        \"layers\": {\n",
    "            \"channels_out\": lambda i: 4 * 2 ** i,\n",
    "            \"kernel_size\": 3\n",
    "        },\n",
    "        \"activations\": {\n",
    "            \"module\": nn.LeakyReLU,\n",
    "            \"inplace\": True\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Syntax 5\n",
    "model = Encoder(\n",
    "    **{\n",
    "        \"depth\": 3,\n",
    "        \"layers.channels_out\": lambda i: 4 * 2 ** i,\n",
    "        \"layers.kernel_size\": 3,\n",
    "        \"activations.module\": nn.LeakyReLU,\n",
    "        \"activations.inplace\": True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    depth : int, optional\n",
    "        Number of layers in the encoder.\n",
    "    layers : dict, LayerConfig, optional\n",
    "        Layer config for each layer in the encoder.\n",
    "            \"\"\"\n",
    "\n",
    "    defaults = {\n",
    "        \"blocks\": dtm.Layer(\"layer\") >> dtm.Layer(\"activation\") >> dtm.Layer(\"normalization\") >> dtm.Layer(\"pool\"),\n",
    "        \"layer.module\": nn.Conv2d,\n",
    "        \"layer.channels_out\": lambda i: 8 * 2 ** i,\n",
    "        \"layer.kernel_size\": 3,\n",
    "        \"layer.padding\": 1,\n",
    "        \"activation.module\": nn.ReLU,\n",
    "        \"normalization.module\": nn.BatchNorm2d,\n",
    "        \"pool.module\": nn.MaxPool2d,\n",
    "        \"pool.kernel_size\": 2,\n",
    "        \"pool.stride\": 2,\n",
    "    }\n",
    "\n",
    "    def __init__(self, depth=4, blocks=None):\n",
    "\n",
    "        super().__init__(depth=depth, blocks=blocks)\n",
    "        \n",
    "        self.depth = self.request(\"depth\")\n",
    "        self.layers = [self.request(\"block\", i) for i in range(self.depth)]\n",
    "\n",
    "    def forward(self, x): \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "convolution_block = dtm.Layer(\"layer\") >> dtm.Layer(\"activation\") >> dtm.Layer(\"normalization\")\n",
    "    \n",
    "resnet_block = dtm.Layer(\"input\") >> convolution_block >> convolution_block\n",
    "resnet_block = (dtm.Layer(\"input\") + resnet_block) >> dtm.Layer(\"normalization\")\n",
    "\n",
    "model = Encoder(\n",
    "    depth=3,\n",
    "    blocks=dtm.Config()\n",
    "            .blocks(resnet_block)\n",
    "            .layer.channels_out(lambda i: 4 * 2 ** i)\n",
    "            .layer.kernel_size(3)\n",
    "            .activation.module(nn.LeakyReLU)\n",
    "            .activation.inplace(True)\n",
    ")\n",
    "\n",
    "\n",
    "model_with_resnet_block = Encoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
